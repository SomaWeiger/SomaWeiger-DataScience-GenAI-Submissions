{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SomaWeiger/SomaWeiger-DataScience-GenAI-Submissions/blob/main/Week_6_Asynchronous/6_02_DNN_101_COMPLETED.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "![](https://drive.google.com/uc?export=view&id=1xqQczl0FG-qtNA2_WQYuWePW9oU8irqJ)"
      ],
      "metadata": {
        "id": "E0T9_-jFXxxc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6.02 Dense Neural Network (with PyTorch)\n",
        "This will expand on our logistic regression example and take us through building our first neural network. If you haven't already, be sure to check (and if neccessary) switch to GPU processing by clicking Runtime > Change runtime type and selecting GPU. We can test this has worked with the following code:"
      ],
      "metadata": {
        "id": "dcEWDwlu94Xs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# Check for GPU availability\n",
        "print(\"Num GPUs Available: \", torch.cuda.device_count())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v8cIpNbCvuQA",
        "outputId": "c2f7b6c0-76a1-443a-e248-7696d35d91df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Num GPUs Available:  1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hopefully your code shows you have 1 GPU available! Next let's get some data. We'll start with another in-built dataset:"
      ],
      "metadata": {
        "id": "8d6FF1wK-ph8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# upload an in-built Python (OK semi-in-built) dataset\n",
        "from sklearn.datasets import load_diabetes\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# import the data\n",
        "data = load_diabetes()\n",
        "data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2MziWWXu-0ur",
        "outputId": "00a16d0d-0f78-4328-ccf3-0c1bff620357"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'data': array([[ 0.03807591,  0.05068012,  0.06169621, ..., -0.00259226,\n",
              "          0.01990749, -0.01764613],\n",
              "        [-0.00188202, -0.04464164, -0.05147406, ..., -0.03949338,\n",
              "         -0.06833155, -0.09220405],\n",
              "        [ 0.08529891,  0.05068012,  0.04445121, ..., -0.00259226,\n",
              "          0.00286131, -0.02593034],\n",
              "        ...,\n",
              "        [ 0.04170844,  0.05068012, -0.01590626, ..., -0.01107952,\n",
              "         -0.04688253,  0.01549073],\n",
              "        [-0.04547248, -0.04464164,  0.03906215, ...,  0.02655962,\n",
              "          0.04452873, -0.02593034],\n",
              "        [-0.04547248, -0.04464164, -0.0730303 , ..., -0.03949338,\n",
              "         -0.00422151,  0.00306441]]),\n",
              " 'target': array([151.,  75., 141., 206., 135.,  97., 138.,  63., 110., 310., 101.,\n",
              "         69., 179., 185., 118., 171., 166., 144.,  97., 168.,  68.,  49.,\n",
              "         68., 245., 184., 202., 137.,  85., 131., 283., 129.,  59., 341.,\n",
              "         87.,  65., 102., 265., 276., 252.,  90., 100.,  55.,  61.,  92.,\n",
              "        259.,  53., 190., 142.,  75., 142., 155., 225.,  59., 104., 182.,\n",
              "        128.,  52.,  37., 170., 170.,  61., 144.,  52., 128.,  71., 163.,\n",
              "        150.,  97., 160., 178.,  48., 270., 202., 111.,  85.,  42., 170.,\n",
              "        200., 252., 113., 143.,  51.,  52., 210.,  65., 141.,  55., 134.,\n",
              "         42., 111.,  98., 164.,  48.,  96.,  90., 162., 150., 279.,  92.,\n",
              "         83., 128., 102., 302., 198.,  95.,  53., 134., 144., 232.,  81.,\n",
              "        104.,  59., 246., 297., 258., 229., 275., 281., 179., 200., 200.,\n",
              "        173., 180.,  84., 121., 161.,  99., 109., 115., 268., 274., 158.,\n",
              "        107.,  83., 103., 272.,  85., 280., 336., 281., 118., 317., 235.,\n",
              "         60., 174., 259., 178., 128.,  96., 126., 288.,  88., 292.,  71.,\n",
              "        197., 186.,  25.,  84.,  96., 195.,  53., 217., 172., 131., 214.,\n",
              "         59.,  70., 220., 268., 152.,  47.,  74., 295., 101., 151., 127.,\n",
              "        237., 225.,  81., 151., 107.,  64., 138., 185., 265., 101., 137.,\n",
              "        143., 141.,  79., 292., 178.,  91., 116.,  86., 122.,  72., 129.,\n",
              "        142.,  90., 158.,  39., 196., 222., 277.,  99., 196., 202., 155.,\n",
              "         77., 191.,  70.,  73.,  49.,  65., 263., 248., 296., 214., 185.,\n",
              "         78.,  93., 252., 150.,  77., 208.,  77., 108., 160.,  53., 220.,\n",
              "        154., 259.,  90., 246., 124.,  67.,  72., 257., 262., 275., 177.,\n",
              "         71.,  47., 187., 125.,  78.,  51., 258., 215., 303., 243.,  91.,\n",
              "        150., 310., 153., 346.,  63.,  89.,  50.,  39., 103., 308., 116.,\n",
              "        145.,  74.,  45., 115., 264.,  87., 202., 127., 182., 241.,  66.,\n",
              "         94., 283.,  64., 102., 200., 265.,  94., 230., 181., 156., 233.,\n",
              "         60., 219.,  80.,  68., 332., 248.,  84., 200.,  55.,  85.,  89.,\n",
              "         31., 129.,  83., 275.,  65., 198., 236., 253., 124.,  44., 172.,\n",
              "        114., 142., 109., 180., 144., 163., 147.,  97., 220., 190., 109.,\n",
              "        191., 122., 230., 242., 248., 249., 192., 131., 237.,  78., 135.,\n",
              "        244., 199., 270., 164.,  72.,  96., 306.,  91., 214.,  95., 216.,\n",
              "        263., 178., 113., 200., 139., 139.,  88., 148.,  88., 243.,  71.,\n",
              "         77., 109., 272.,  60.,  54., 221.,  90., 311., 281., 182., 321.,\n",
              "         58., 262., 206., 233., 242., 123., 167.,  63., 197.,  71., 168.,\n",
              "        140., 217., 121., 235., 245.,  40.,  52., 104., 132.,  88.,  69.,\n",
              "        219.,  72., 201., 110.,  51., 277.,  63., 118.,  69., 273., 258.,\n",
              "         43., 198., 242., 232., 175.,  93., 168., 275., 293., 281.,  72.,\n",
              "        140., 189., 181., 209., 136., 261., 113., 131., 174., 257.,  55.,\n",
              "         84.,  42., 146., 212., 233.,  91., 111., 152., 120.,  67., 310.,\n",
              "         94., 183.,  66., 173.,  72.,  49.,  64.,  48., 178., 104., 132.,\n",
              "        220.,  57.]),\n",
              " 'frame': None,\n",
              " 'DESCR': '.. _diabetes_dataset:\\n\\nDiabetes dataset\\n----------------\\n\\nTen baseline variables, age, sex, body mass index, average blood\\npressure, and six blood serum measurements were obtained for each of n =\\n442 diabetes patients, as well as the response of interest, a\\nquantitative measure of disease progression one year after baseline.\\n\\n**Data Set Characteristics:**\\n\\n:Number of Instances: 442\\n\\n:Number of Attributes: First 10 columns are numeric predictive values\\n\\n:Target: Column 11 is a quantitative measure of disease progression one year after baseline\\n\\n:Attribute Information:\\n    - age     age in years\\n    - sex\\n    - bmi     body mass index\\n    - bp      average blood pressure\\n    - s1      tc, total serum cholesterol\\n    - s2      ldl, low-density lipoproteins\\n    - s3      hdl, high-density lipoproteins\\n    - s4      tch, total cholesterol / HDL\\n    - s5      ltg, possibly log of serum triglycerides level\\n    - s6      glu, blood sugar level\\n\\nNote: Each of these 10 feature variables have been mean centered and scaled by the standard deviation times the square root of `n_samples` (i.e. the sum of squares of each column totals 1).\\n\\nSource URL:\\nhttps://www4.stat.ncsu.edu/~boos/var.select/diabetes.html\\n\\nFor more information see:\\nBradley Efron, Trevor Hastie, Iain Johnstone and Robert Tibshirani (2004) \"Least Angle Regression,\" Annals of Statistics (with discussion), 407-499.\\n(https://web.stanford.edu/~hastie/Papers/LARS/LeastAngle_2002.pdf)\\n',\n",
              " 'feature_names': ['age',\n",
              "  'sex',\n",
              "  'bmi',\n",
              "  'bp',\n",
              "  's1',\n",
              "  's2',\n",
              "  's3',\n",
              "  's4',\n",
              "  's5',\n",
              "  's6'],\n",
              " 'data_filename': 'diabetes_data_raw.csv.gz',\n",
              " 'target_filename': 'diabetes_target.csv.gz',\n",
              " 'data_module': 'sklearn.datasets.data'}"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We are working on a regression problem, with \"structured\" data which has already been cleaned and normalised. We can skip the usual cleaning/engineering steps. However, we do need to get the data into PyTorch:"
      ],
      "metadata": {
        "id": "cZKrbx70_cIT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert data to PyTorch tensors\n",
        "X = torch.tensor(data.data, dtype=torch.float32)\n",
        "y = torch.tensor(data.target, dtype=torch.float32).reshape(-1, 1) # Reshape y to be a column vector"
      ],
      "metadata": {
        "id": "f9PHiljr73fI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now our data is stored in tensors we can do train/test splitting as before (in fact we can use sklearn as before):"
      ],
      "metadata": {
        "id": "hu8VH2_SAOoj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "print(X_train.shape, y_train.shape)\n",
        "print(X_test.shape, y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PYJN01DV8Fac",
        "outputId": "68e87954-4e8c-4d4a-c2ec-8436e17324d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([353, 10]) torch.Size([353, 1])\n",
            "torch.Size([89, 10]) torch.Size([89, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we can set up our batches for training. As we have a nice round 400 let's go with batches of 50 (8 batches in total). We'll also seperate the features and labels:"
      ],
      "metadata": {
        "id": "LKmbZoCrJijU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "# Create TensorDatasets and DataLoaders\n",
        "train_dataset = TensorDataset(X_train, y_train)\n",
        "train_loader = DataLoader(train_dataset, batch_size=50, shuffle=True)\n",
        "\n",
        "test_dataset = TensorDataset(X_test, y_test)\n",
        "test_loader = DataLoader(test_dataset, batch_size=50, shuffle=False)"
      ],
      "metadata": {
        "id": "de0uOko08d-K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now its time to build our model. We'll keep it simple ... a model with an input layer of 10 features and then 2x _Dense_ (fully connected) layers each with 5 neurons and ReLU activation. Our output layer will be size=1 given this is a regression problem and we want a single value output per prediction.\n",
        "\n",
        "This will be easier to understand if you have read through the logistic regression tutorial."
      ],
      "metadata": {
        "id": "yCCG8kKHCVnd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# Define the model\n",
        "class DiabetesModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(DiabetesModel, self).__init__()\n",
        "        # we'll set up the layers as a sequence using nn.Sequential\n",
        "        self.layers = nn.Sequential(\n",
        "\n",
        "            # first layer will be a linear layer that has 5x neurons\n",
        "            # (5x sets of linear regression)\n",
        "            # the layer takes the 10 features as input (i.e. 10, 5)\n",
        "            nn.Linear(10, 5),\n",
        "\n",
        "            nn.ReLU(), # ReLU activation\n",
        "\n",
        "            # second linear layer again has 5 neurons\n",
        "            # this time taking the input as the output of the last layer\n",
        "            # (which had 5x neurons)\n",
        "            nn.Linear(5, 5),\n",
        "\n",
        "            nn.ReLU(), # ReLU again\n",
        "\n",
        "            # last linear layer takes the output from the previous 5 neurons\n",
        "            # this time its a single output with no activation\n",
        "            # i.e. this is the predicitons (regression)\n",
        "            nn.Linear(5, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.layers(x) # pass the data through the layers"
      ],
      "metadata": {
        "id": "844H60hcCV3s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As before we need to create a model object, specify the loss (criterion) and an optimiser (which we cover next week):"
      ],
      "metadata": {
        "id": "cv4-loCz91aa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "# Initialize the model, loss function, and optimizer\n",
        "model = DiabetesModel()\n",
        "criterion = nn.MSELoss() # MSE loss function\n",
        "optimiser = optim.Adam(model.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "EPx_Wy6g9uA4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we can train the model. Again, the logistic regression tutorial (6.01) may help you undertstand this:"
      ],
      "metadata": {
        "id": "HOKfjkfW-Ish"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Move model to GPU if available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Training loop (example - you'll likely want to add more epochs)\n",
        "epochs = 100 # 100 epochs\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  # use the train_loader to pass the inputs (x) and targets (y)\n",
        "  for inputs, targets in train_loader:\n",
        "    # pass to the GPU (hopefully)\n",
        "    inputs, targets = inputs.to(device), targets.to(device)\n",
        "\n",
        "    # pass model to GPU as well\n",
        "    model.to(device)\n",
        "\n",
        "    model.train() # put the model object in train mode\n",
        "    optimiser.zero_grad() # reset the gradiants\n",
        "    outputs = model(inputs) # create outputs\n",
        "    loss = criterion(outputs, targets) # compare with Y to get loss\n",
        "    loss.backward() # backpropogate the loss (next week)\n",
        "    optimiser.step() # # update the parameters based on this round of training\n",
        "\n",
        "  # every 10 steps we will print out the current loss\n",
        "    if (epoch+1) % 10 == 0: # modular arithmetic\n",
        "        print(f'Epoch [{epoch+1}/{epochs}], Loss: {round(loss.item(), 4)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PtMUgfwT-HGt",
        "outputId": "07c49e9f-a6ec-45ba-bb43-dca5068b4709"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [10/100], Loss: 31614.834\n",
            "Epoch [10/100], Loss: 35444.5\n",
            "Epoch [10/100], Loss: 25765.7402\n",
            "Epoch [10/100], Loss: 28617.8789\n",
            "Epoch [10/100], Loss: 28595.3652\n",
            "Epoch [10/100], Loss: 28912.0586\n",
            "Epoch [10/100], Loss: 29359.4062\n",
            "Epoch [10/100], Loss: 4102.7739\n",
            "Epoch [20/100], Loss: 27254.3926\n",
            "Epoch [20/100], Loss: 31732.832\n",
            "Epoch [20/100], Loss: 26878.1992\n",
            "Epoch [20/100], Loss: 30481.7852\n",
            "Epoch [20/100], Loss: 31530.4609\n",
            "Epoch [20/100], Loss: 27179.3145\n",
            "Epoch [20/100], Loss: 30038.9902\n",
            "Epoch [20/100], Loss: 47833.9297\n",
            "Epoch [30/100], Loss: 34002.9961\n",
            "Epoch [30/100], Loss: 27538.4688\n",
            "Epoch [30/100], Loss: 32546.5469\n",
            "Epoch [30/100], Loss: 27602.9766\n",
            "Epoch [30/100], Loss: 27147.0312\n",
            "Epoch [30/100], Loss: 24788.4375\n",
            "Epoch [30/100], Loss: 30520.1035\n",
            "Epoch [30/100], Loss: 50024.2812\n",
            "Epoch [40/100], Loss: 30036.9941\n",
            "Epoch [40/100], Loss: 33633.5703\n",
            "Epoch [40/100], Loss: 28206.4199\n",
            "Epoch [40/100], Loss: 23854.334\n",
            "Epoch [40/100], Loss: 25582.9941\n",
            "Epoch [40/100], Loss: 29767.4336\n",
            "Epoch [40/100], Loss: 32904.1094\n",
            "Epoch [40/100], Loss: 23879.043\n",
            "Epoch [50/100], Loss: 30826.4609\n",
            "Epoch [50/100], Loss: 28332.2598\n",
            "Epoch [50/100], Loss: 27471.3203\n",
            "Epoch [50/100], Loss: 23244.5977\n",
            "Epoch [50/100], Loss: 31669.1387\n",
            "Epoch [50/100], Loss: 32023.0977\n",
            "Epoch [50/100], Loss: 26392.6836\n",
            "Epoch [50/100], Loss: 35651.6797\n",
            "Epoch [60/100], Loss: 23249.6699\n",
            "Epoch [60/100], Loss: 31158.8535\n",
            "Epoch [60/100], Loss: 27914.2441\n",
            "Epoch [60/100], Loss: 34732.2344\n",
            "Epoch [60/100], Loss: 23417.0547\n",
            "Epoch [60/100], Loss: 28298.9316\n",
            "Epoch [60/100], Loss: 24420.0898\n",
            "Epoch [60/100], Loss: 48743.0703\n",
            "Epoch [70/100], Loss: 27805.082\n",
            "Epoch [70/100], Loss: 23622.5801\n",
            "Epoch [70/100], Loss: 31622.959\n",
            "Epoch [70/100], Loss: 24959.2793\n",
            "Epoch [70/100], Loss: 23202.375\n",
            "Epoch [70/100], Loss: 26025.5098\n",
            "Epoch [70/100], Loss: 26725.2246\n",
            "Epoch [70/100], Loss: 20519.5898\n",
            "Epoch [80/100], Loss: 27174.0664\n",
            "Epoch [80/100], Loss: 19419.4492\n",
            "Epoch [80/100], Loss: 20577.9102\n",
            "Epoch [80/100], Loss: 24915.1973\n",
            "Epoch [80/100], Loss: 21232.75\n",
            "Epoch [80/100], Loss: 30249.4746\n",
            "Epoch [80/100], Loss: 23979.125\n",
            "Epoch [80/100], Loss: 41130.4023\n",
            "Epoch [90/100], Loss: 24504.1953\n",
            "Epoch [90/100], Loss: 17628.5664\n",
            "Epoch [90/100], Loss: 24214.6191\n",
            "Epoch [90/100], Loss: 23597.666\n",
            "Epoch [90/100], Loss: 19988.3477\n",
            "Epoch [90/100], Loss: 22452.0703\n",
            "Epoch [90/100], Loss: 18908.7188\n",
            "Epoch [90/100], Loss: 5441.2168\n",
            "Epoch [100/100], Loss: 19482.834\n",
            "Epoch [100/100], Loss: 19736.4023\n",
            "Epoch [100/100], Loss: 11995.4912\n",
            "Epoch [100/100], Loss: 16705.3984\n",
            "Epoch [100/100], Loss: 24539.7812\n",
            "Epoch [100/100], Loss: 20929.8418\n",
            "Epoch [100/100], Loss: 16286.0332\n",
            "Epoch [100/100], Loss: 16836.5234\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see loss is significantly lower at the end than it was at the start. However, it is also bouncing around a little still which suggests the model needs more training (100 epochs is not a lot in deep learning terms). However, let's evaluate as before:"
      ],
      "metadata": {
        "id": "E72ZTKSqAODE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval() # testing mode\n",
        "mse_values = [] # collect the MSE scores\n",
        "\n",
        "with torch.no_grad():\n",
        "    for inputs, targets in test_loader:\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "        outputs = model(inputs) # predict the test data\n",
        "\n",
        "        # Calculate Mean Squared Error\n",
        "        mse = criterion(outputs, targets) # calcualte mse for the batch\n",
        "        mse_values.append(mse.item()) # add to the list of MSE values\n",
        "\n",
        "# Calculate and print the average MSE\n",
        "avg_mse_1000_epochs = np.mean(mse_values)\n",
        "print(f\"Average MSE on test set after 1000 epochs: {avg_mse_1000_epochs}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RbuAH6p8A-Vh",
        "outputId": "e310511e-fbe5-46cd-d302-58cdf5c53756"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average MSE on test set after 1000 epochs: 2862.158203125\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "MSE looks expected given training (no obvious sign of overfitting). However, we probably can get better results with tuning and more epochs.\n",
        "\n",
        "Let's run the loop again a little differently to collect the predicted values (y_hat) and actuals (y) and add them to a dataset for comparions:"
      ],
      "metadata": {
        "id": "HQ26bA08Up12"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation\n",
        "model.eval()\n",
        "predictions_1000_epochs = []\n",
        "actuals_1000_epochs = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for inputs, targets in test_loader:\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "        outputs = model(inputs)\n",
        "        predictions_1000_epochs.extend(outputs.cpu().numpy())\n",
        "        actuals_1000_epochs.extend(targets.cpu().numpy())\n",
        "\n",
        "# Create DataFrame\n",
        "results_df_1000_epochs = pd.DataFrame({'Predicted': np.array(predictions_1000_epochs).flatten(), 'Actual': np.array(actuals_1000_epochs).flatten()})\n",
        "display(results_df_1000_epochs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "8AYsDDSLUp_u",
        "outputId": "c23f8dad-ffe6-46a0-e2ce-db87694d2b84"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "     Predicted  Actual\n",
              "0   143.103439   219.0\n",
              "1   178.147659    70.0\n",
              "2   139.159027   202.0\n",
              "3   295.722900   230.0\n",
              "4   123.695450   111.0\n",
              "..         ...     ...\n",
              "84  115.172958   153.0\n",
              "85   87.421288    98.0\n",
              "86   78.077057    37.0\n",
              "87   64.696053    63.0\n",
              "88  155.820312   184.0\n",
              "\n",
              "[89 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8aeb8f9c-9ff3-44c1-a9dc-e87680f0c040\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Predicted</th>\n",
              "      <th>Actual</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>143.103439</td>\n",
              "      <td>219.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>178.147659</td>\n",
              "      <td>70.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>139.159027</td>\n",
              "      <td>202.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>295.722900</td>\n",
              "      <td>230.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>123.695450</td>\n",
              "      <td>111.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>84</th>\n",
              "      <td>115.172958</td>\n",
              "      <td>153.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>85</th>\n",
              "      <td>87.421288</td>\n",
              "      <td>98.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>86</th>\n",
              "      <td>78.077057</td>\n",
              "      <td>37.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>87</th>\n",
              "      <td>64.696053</td>\n",
              "      <td>63.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88</th>\n",
              "      <td>155.820312</td>\n",
              "      <td>184.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>89 rows Ã— 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8aeb8f9c-9ff3-44c1-a9dc-e87680f0c040')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-8aeb8f9c-9ff3-44c1-a9dc-e87680f0c040 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-8aeb8f9c-9ff3-44c1-a9dc-e87680f0c040');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-9244eb88-b57c-4086-b507-aa22fe849d92\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-9244eb88-b57c-4086-b507-aa22fe849d92')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-9244eb88-b57c-4086-b507-aa22fe849d92 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_3898d71e-f4bd-4b2f-835f-b5ad2ae3265b\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('results_df_1000_epochs')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_3898d71e-f4bd-4b2f-835f-b5ad2ae3265b button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('results_df_1000_epochs');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "results_df_1000_epochs",
              "summary": "{\n  \"name\": \"results_df_1000_epochs\",\n  \"rows\": 89,\n  \"fields\": [\n    {\n      \"column\": \"Predicted\",\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"num_unique_values\": 89,\n        \"samples\": [\n          177.3844757080078,\n          110.56366729736328,\n          177.12660217285156\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Actual\",\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"num_unique_values\": 75,\n        \"samples\": [\n          111.0,\n          61.0,\n          252.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Side-by-side, they don't look great. Can you improve them?\n",
        "\n",
        "<br><br>\n",
        "\n",
        "## EXERCISE #1\n",
        "Try increasing the number of epochs to 1,000 (when the model is fairly well trained then the results printed for each 10x epochs will be fairly stable and not change much). Does this give better results?\n",
        "\n",
        "<br><br>\n",
        "\n",
        "## EXERCISE #2 (optional)\n",
        "Try experimenting with the architecture (number of neurons and/or number of layers). Can we reach an optimal architecture?"
      ],
      "metadata": {
        "id": "LDcM98lHbgP8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Exercise 1"
      ],
      "metadata": {
        "id": "wovfGrJLRP1Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Move model to GPU if available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Training loop (increasing number of epochs to 1000, from 100)\n",
        "epochs = 1000 # 1000 epochs\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  # use the train_loader to pass the inputs (x) and targets (y)\n",
        "  for inputs, targets in train_loader:\n",
        "    # pass to the GPU (hopefully)\n",
        "    inputs, targets = inputs.to(device), targets.to(device)\n",
        "\n",
        "    # pass model to GPU as well\n",
        "    model.to(device)\n",
        "\n",
        "    model.train() # put the model object in train mode\n",
        "    optimiser.zero_grad() # reset the gradiants\n",
        "    outputs = model(inputs) # create outputs\n",
        "    loss = criterion(outputs, targets) # compare with Y to get loss\n",
        "    loss.backward() # backpropogate the loss (next week)\n",
        "    optimiser.step() # # update the parameters based on this round of training\n",
        "\n",
        "  # every 10 steps we will print out the current loss\n",
        "    if (epoch+1) % 10 == 0: # modular arithmetic\n",
        "        print(f'Epoch [{epoch+1}/{epochs}], Loss: {round(loss.item(), 4)}')"
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IM0KMXhRRUFB",
        "outputId": "0c876c7d-5ab7-4b62-f350-bc9e19d72004"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [10/1000], Loss: 13615.7451\n",
            "Epoch [10/1000], Loss: 16522.9434\n",
            "Epoch [10/1000], Loss: 13005.6299\n",
            "Epoch [10/1000], Loss: 18375.2305\n",
            "Epoch [10/1000], Loss: 15236.0557\n",
            "Epoch [10/1000], Loss: 15727.6533\n",
            "Epoch [10/1000], Loss: 15873.4717\n",
            "Epoch [10/1000], Loss: 6291.3101\n",
            "Epoch [20/1000], Loss: 11495.2598\n",
            "Epoch [20/1000], Loss: 10060.9434\n",
            "Epoch [20/1000], Loss: 13462.8936\n",
            "Epoch [20/1000], Loss: 16964.7344\n",
            "Epoch [20/1000], Loss: 13776.8389\n",
            "Epoch [20/1000], Loss: 8916.3789\n",
            "Epoch [20/1000], Loss: 12320.8477\n",
            "Epoch [20/1000], Loss: 16877.1621\n",
            "Epoch [30/1000], Loss: 10328.3184\n",
            "Epoch [30/1000], Loss: 8496.1377\n",
            "Epoch [30/1000], Loss: 14042.0176\n",
            "Epoch [30/1000], Loss: 7846.1172\n",
            "Epoch [30/1000], Loss: 10315.9512\n",
            "Epoch [30/1000], Loss: 8875.2393\n",
            "Epoch [30/1000], Loss: 8884.834\n",
            "Epoch [30/1000], Loss: 7385.9043\n",
            "Epoch [40/1000], Loss: 8967.8105\n",
            "Epoch [40/1000], Loss: 8810.7607\n",
            "Epoch [40/1000], Loss: 6387.4312\n",
            "Epoch [40/1000], Loss: 8201.3496\n",
            "Epoch [40/1000], Loss: 6891.626\n",
            "Epoch [40/1000], Loss: 9690.3994\n",
            "Epoch [40/1000], Loss: 5299.3579\n",
            "Epoch [40/1000], Loss: 7045.8086\n",
            "Epoch [50/1000], Loss: 5928.4644\n",
            "Epoch [50/1000], Loss: 6182.4224\n",
            "Epoch [50/1000], Loss: 6241.4067\n",
            "Epoch [50/1000], Loss: 7524.1128\n",
            "Epoch [50/1000], Loss: 5047.5337\n",
            "Epoch [50/1000], Loss: 6971.1899\n",
            "Epoch [50/1000], Loss: 6502.8188\n",
            "Epoch [50/1000], Loss: 3459.2578\n",
            "Epoch [60/1000], Loss: 5132.4399\n",
            "Epoch [60/1000], Loss: 4787.6841\n",
            "Epoch [60/1000], Loss: 4520.064\n",
            "Epoch [60/1000], Loss: 5895.71\n",
            "Epoch [60/1000], Loss: 5541.9761\n",
            "Epoch [60/1000], Loss: 5970.3672\n",
            "Epoch [60/1000], Loss: 4848.2588\n",
            "Epoch [60/1000], Loss: 9838.3711\n",
            "Epoch [70/1000], Loss: 5177.5029\n",
            "Epoch [70/1000], Loss: 4591.0269\n",
            "Epoch [70/1000], Loss: 4291.7241\n",
            "Epoch [70/1000], Loss: 3796.9084\n",
            "Epoch [70/1000], Loss: 5267.8413\n",
            "Epoch [70/1000], Loss: 5464.7388\n",
            "Epoch [70/1000], Loss: 4468.5854\n",
            "Epoch [70/1000], Loss: 1842.8773\n",
            "Epoch [80/1000], Loss: 4738.8589\n",
            "Epoch [80/1000], Loss: 4676.1035\n",
            "Epoch [80/1000], Loss: 4072.5081\n",
            "Epoch [80/1000], Loss: 3966.2393\n",
            "Epoch [80/1000], Loss: 5194.271\n",
            "Epoch [80/1000], Loss: 4905.833\n",
            "Epoch [80/1000], Loss: 3409.5427\n",
            "Epoch [80/1000], Loss: 4407.54\n",
            "Epoch [90/1000], Loss: 5042.9912\n",
            "Epoch [90/1000], Loss: 3927.553\n",
            "Epoch [90/1000], Loss: 3871.6887\n",
            "Epoch [90/1000], Loss: 4197.3984\n",
            "Epoch [90/1000], Loss: 4587.2266\n",
            "Epoch [90/1000], Loss: 3723.8037\n",
            "Epoch [90/1000], Loss: 4613.644\n",
            "Epoch [90/1000], Loss: 1088.4059\n",
            "Epoch [100/1000], Loss: 4049.8794\n",
            "Epoch [100/1000], Loss: 4557.5854\n",
            "Epoch [100/1000], Loss: 5146.3018\n",
            "Epoch [100/1000], Loss: 4083.9346\n",
            "Epoch [100/1000], Loss: 2882.2874\n",
            "Epoch [100/1000], Loss: 3737.1387\n",
            "Epoch [100/1000], Loss: 4504.0166\n",
            "Epoch [100/1000], Loss: 5424.5244\n",
            "Epoch [110/1000], Loss: 3614.3108\n",
            "Epoch [110/1000], Loss: 4567.0566\n",
            "Epoch [110/1000], Loss: 3606.1567\n",
            "Epoch [110/1000], Loss: 3888.3606\n",
            "Epoch [110/1000], Loss: 5011.9976\n",
            "Epoch [110/1000], Loss: 3455.4524\n",
            "Epoch [110/1000], Loss: 4258.9351\n",
            "Epoch [110/1000], Loss: 7773.6758\n",
            "Epoch [120/1000], Loss: 3285.9609\n",
            "Epoch [120/1000], Loss: 4880.2534\n",
            "Epoch [120/1000], Loss: 3698.2993\n",
            "Epoch [120/1000], Loss: 3967.5742\n",
            "Epoch [120/1000], Loss: 3935.7617\n",
            "Epoch [120/1000], Loss: 4784.7368\n",
            "Epoch [120/1000], Loss: 3740.9153\n",
            "Epoch [120/1000], Loss: 2577.2996\n",
            "Epoch [130/1000], Loss: 4511.0737\n",
            "Epoch [130/1000], Loss: 3538.678\n",
            "Epoch [130/1000], Loss: 4156.4512\n",
            "Epoch [130/1000], Loss: 3431.8359\n",
            "Epoch [130/1000], Loss: 3820.0886\n",
            "Epoch [130/1000], Loss: 3738.4949\n",
            "Epoch [130/1000], Loss: 4587.769\n",
            "Epoch [130/1000], Loss: 5681.7051\n",
            "Epoch [140/1000], Loss: 4062.8015\n",
            "Epoch [140/1000], Loss: 3873.0598\n",
            "Epoch [140/1000], Loss: 3191.741\n",
            "Epoch [140/1000], Loss: 4872.7856\n",
            "Epoch [140/1000], Loss: 3988.9475\n",
            "Epoch [140/1000], Loss: 4240.4751\n",
            "Epoch [140/1000], Loss: 3228.5872\n",
            "Epoch [140/1000], Loss: 6285.98\n",
            "Epoch [150/1000], Loss: 4337.7622\n",
            "Epoch [150/1000], Loss: 2615.2986\n",
            "Epoch [150/1000], Loss: 3577.3486\n",
            "Epoch [150/1000], Loss: 3951.3855\n",
            "Epoch [150/1000], Loss: 4732.6113\n",
            "Epoch [150/1000], Loss: 4163.5269\n",
            "Epoch [150/1000], Loss: 3539.7769\n",
            "Epoch [150/1000], Loss: 10647.4258\n",
            "Epoch [160/1000], Loss: 4720.5151\n",
            "Epoch [160/1000], Loss: 4264.9463\n",
            "Epoch [160/1000], Loss: 3422.7104\n",
            "Epoch [160/1000], Loss: 4178.1562\n",
            "Epoch [160/1000], Loss: 4290.083\n",
            "Epoch [160/1000], Loss: 3111.0818\n",
            "Epoch [160/1000], Loss: 3087.6746\n",
            "Epoch [160/1000], Loss: 3285.7908\n",
            "Epoch [170/1000], Loss: 2625.0569\n",
            "Epoch [170/1000], Loss: 4170.1982\n",
            "Epoch [170/1000], Loss: 3656.4705\n",
            "Epoch [170/1000], Loss: 4692.4292\n",
            "Epoch [170/1000], Loss: 4240.6475\n",
            "Epoch [170/1000], Loss: 4576.4292\n",
            "Epoch [170/1000], Loss: 2977.9792\n",
            "Epoch [170/1000], Loss: 1008.4219\n",
            "Epoch [180/1000], Loss: 3019.6594\n",
            "Epoch [180/1000], Loss: 3407.6384\n",
            "Epoch [180/1000], Loss: 4110.1025\n",
            "Epoch [180/1000], Loss: 3758.2957\n",
            "Epoch [180/1000], Loss: 3928.5073\n",
            "Epoch [180/1000], Loss: 4889.6787\n",
            "Epoch [180/1000], Loss: 3519.6396\n",
            "Epoch [180/1000], Loss: 1908.4662\n",
            "Epoch [190/1000], Loss: 3506.7075\n",
            "Epoch [190/1000], Loss: 3128.5754\n",
            "Epoch [190/1000], Loss: 3480.9946\n",
            "Epoch [190/1000], Loss: 3820.7192\n",
            "Epoch [190/1000], Loss: 4042.4832\n",
            "Epoch [190/1000], Loss: 4071.6521\n",
            "Epoch [190/1000], Loss: 4349.3652\n",
            "Epoch [190/1000], Loss: 1572.0868\n",
            "Epoch [200/1000], Loss: 3606.8721\n",
            "Epoch [200/1000], Loss: 3385.845\n",
            "Epoch [200/1000], Loss: 3175.9336\n",
            "Epoch [200/1000], Loss: 3635.3879\n",
            "Epoch [200/1000], Loss: 3355.075\n",
            "Epoch [200/1000], Loss: 4626.0562\n",
            "Epoch [200/1000], Loss: 4146.0288\n",
            "Epoch [200/1000], Loss: 5712.8467\n",
            "Epoch [210/1000], Loss: 3199.7292\n",
            "Epoch [210/1000], Loss: 4085.0552\n",
            "Epoch [210/1000], Loss: 4726.418\n",
            "Epoch [210/1000], Loss: 2753.3694\n",
            "Epoch [210/1000], Loss: 2722.4868\n",
            "Epoch [210/1000], Loss: 4560.5195\n",
            "Epoch [210/1000], Loss: 3932.5967\n",
            "Epoch [210/1000], Loss: 1496.4125\n",
            "Epoch [220/1000], Loss: 4011.7681\n",
            "Epoch [220/1000], Loss: 3606.98\n",
            "Epoch [220/1000], Loss: 4499.7495\n",
            "Epoch [220/1000], Loss: 3114.2405\n",
            "Epoch [220/1000], Loss: 3367.9275\n",
            "Epoch [220/1000], Loss: 3378.9934\n",
            "Epoch [220/1000], Loss: 3568.6711\n",
            "Epoch [220/1000], Loss: 4596.8032\n",
            "Epoch [230/1000], Loss: 3376.9124\n",
            "Epoch [230/1000], Loss: 4120.8262\n",
            "Epoch [230/1000], Loss: 4023.5933\n",
            "Epoch [230/1000], Loss: 2873.7146\n",
            "Epoch [230/1000], Loss: 3504.5925\n",
            "Epoch [230/1000], Loss: 4003.8638\n",
            "Epoch [230/1000], Loss: 3400.5583\n",
            "Epoch [230/1000], Loss: 5643.7725\n",
            "Epoch [240/1000], Loss: 4159.0342\n",
            "Epoch [240/1000], Loss: 3780.5959\n",
            "Epoch [240/1000], Loss: 3154.7795\n",
            "Epoch [240/1000], Loss: 3172.3931\n",
            "Epoch [240/1000], Loss: 3391.0391\n",
            "Epoch [240/1000], Loss: 3341.3215\n",
            "Epoch [240/1000], Loss: 4278.3091\n",
            "Epoch [240/1000], Loss: 2691.0649\n",
            "Epoch [250/1000], Loss: 3446.2461\n",
            "Epoch [250/1000], Loss: 2709.3157\n",
            "Epoch [250/1000], Loss: 3519.3362\n",
            "Epoch [250/1000], Loss: 4242.6147\n",
            "Epoch [250/1000], Loss: 3494.2124\n",
            "Epoch [250/1000], Loss: 3373.5654\n",
            "Epoch [250/1000], Loss: 4217.4028\n",
            "Epoch [250/1000], Loss: 4009.1406\n",
            "Epoch [260/1000], Loss: 3871.1084\n",
            "Epoch [260/1000], Loss: 3191.3884\n",
            "Epoch [260/1000], Loss: 4153.5288\n",
            "Epoch [260/1000], Loss: 3304.0603\n",
            "Epoch [260/1000], Loss: 3477.0906\n",
            "Epoch [260/1000], Loss: 3734.8149\n",
            "Epoch [260/1000], Loss: 3155.8298\n",
            "Epoch [260/1000], Loss: 2842.6035\n",
            "Epoch [270/1000], Loss: 3154.8865\n",
            "Epoch [270/1000], Loss: 4045.7417\n",
            "Epoch [270/1000], Loss: 3431.0569\n",
            "Epoch [270/1000], Loss: 3800.0481\n",
            "Epoch [270/1000], Loss: 3355.4219\n",
            "Epoch [270/1000], Loss: 2964.0337\n",
            "Epoch [270/1000], Loss: 3831.2336\n",
            "Epoch [270/1000], Loss: 4835.1328\n",
            "Epoch [280/1000], Loss: 3155.2759\n",
            "Epoch [280/1000], Loss: 3048.4983\n",
            "Epoch [280/1000], Loss: 3224.3962\n",
            "Epoch [280/1000], Loss: 3845.6008\n",
            "Epoch [280/1000], Loss: 4220.5815\n",
            "Epoch [280/1000], Loss: 3881.7405\n",
            "Epoch [280/1000], Loss: 3197.2917\n",
            "Epoch [280/1000], Loss: 2104.4382\n",
            "Epoch [290/1000], Loss: 3055.9995\n",
            "Epoch [290/1000], Loss: 3926.1328\n",
            "Epoch [290/1000], Loss: 3268.217\n",
            "Epoch [290/1000], Loss: 3688.3496\n",
            "Epoch [290/1000], Loss: 3654.5095\n",
            "Epoch [290/1000], Loss: 3062.1411\n",
            "Epoch [290/1000], Loss: 3625.7605\n",
            "Epoch [290/1000], Loss: 4147.9922\n",
            "Epoch [300/1000], Loss: 3776.6067\n",
            "Epoch [300/1000], Loss: 3673.0525\n",
            "Epoch [300/1000], Loss: 3623.0374\n",
            "Epoch [300/1000], Loss: 3505.6924\n",
            "Epoch [300/1000], Loss: 2056.9863\n",
            "Epoch [300/1000], Loss: 3844.7625\n",
            "Epoch [300/1000], Loss: 3796.113\n",
            "Epoch [300/1000], Loss: 1600.4788\n",
            "Epoch [310/1000], Loss: 3221.7168\n",
            "Epoch [310/1000], Loss: 3274.5056\n",
            "Epoch [310/1000], Loss: 2971.6865\n",
            "Epoch [310/1000], Loss: 4328.7568\n",
            "Epoch [310/1000], Loss: 4052.5024\n",
            "Epoch [310/1000], Loss: 2726.8464\n",
            "Epoch [310/1000], Loss: 3595.0281\n",
            "Epoch [310/1000], Loss: 615.761\n",
            "Epoch [320/1000], Loss: 3305.5708\n",
            "Epoch [320/1000], Loss: 3095.3967\n",
            "Epoch [320/1000], Loss: 3860.7656\n",
            "Epoch [320/1000], Loss: 3115.4443\n",
            "Epoch [320/1000], Loss: 2929.1145\n",
            "Epoch [320/1000], Loss: 3539.5605\n",
            "Epoch [320/1000], Loss: 4048.8398\n",
            "Epoch [320/1000], Loss: 2486.1082\n",
            "Epoch [330/1000], Loss: 3493.1807\n",
            "Epoch [330/1000], Loss: 3068.8206\n",
            "Epoch [330/1000], Loss: 2721.6675\n",
            "Epoch [330/1000], Loss: 3811.1619\n",
            "Epoch [330/1000], Loss: 3673.5024\n",
            "Epoch [330/1000], Loss: 3942.144\n",
            "Epoch [330/1000], Loss: 3039.0491\n",
            "Epoch [330/1000], Loss: 2783.9429\n",
            "Epoch [340/1000], Loss: 3745.8762\n",
            "Epoch [340/1000], Loss: 2886.4619\n",
            "Epoch [340/1000], Loss: 3595.1245\n",
            "Epoch [340/1000], Loss: 3318.4399\n",
            "Epoch [340/1000], Loss: 3011.2427\n",
            "Epoch [340/1000], Loss: 3662.241\n",
            "Epoch [340/1000], Loss: 3521.4734\n",
            "Epoch [340/1000], Loss: 496.9068\n",
            "Epoch [350/1000], Loss: 4227.9521\n",
            "Epoch [350/1000], Loss: 3446.9087\n",
            "Epoch [350/1000], Loss: 3017.2\n",
            "Epoch [350/1000], Loss: 3102.3325\n",
            "Epoch [350/1000], Loss: 3343.7305\n",
            "Epoch [350/1000], Loss: 3152.2615\n",
            "Epoch [350/1000], Loss: 3054.583\n",
            "Epoch [350/1000], Loss: 4645.811\n",
            "Epoch [360/1000], Loss: 3846.5356\n",
            "Epoch [360/1000], Loss: 2713.0105\n",
            "Epoch [360/1000], Loss: 3248.7517\n",
            "Epoch [360/1000], Loss: 3092.386\n",
            "Epoch [360/1000], Loss: 4662.6069\n",
            "Epoch [360/1000], Loss: 2456.4312\n",
            "Epoch [360/1000], Loss: 3428.9199\n",
            "Epoch [360/1000], Loss: 1147.8215\n",
            "Epoch [370/1000], Loss: 4246.4751\n",
            "Epoch [370/1000], Loss: 2619.9607\n",
            "Epoch [370/1000], Loss: 3492.6611\n",
            "Epoch [370/1000], Loss: 3230.2629\n",
            "Epoch [370/1000], Loss: 3317.9558\n",
            "Epoch [370/1000], Loss: 2948.49\n",
            "Epoch [370/1000], Loss: 3371.8486\n",
            "Epoch [370/1000], Loss: 2677.7166\n",
            "Epoch [380/1000], Loss: 3255.5938\n",
            "Epoch [380/1000], Loss: 3586.0337\n",
            "Epoch [380/1000], Loss: 2172.5315\n",
            "Epoch [380/1000], Loss: 3843.7\n",
            "Epoch [380/1000], Loss: 3449.2583\n",
            "Epoch [380/1000], Loss: 3652.832\n",
            "Epoch [380/1000], Loss: 3097.4312\n",
            "Epoch [380/1000], Loss: 3353.5\n",
            "Epoch [390/1000], Loss: 2534.354\n",
            "Epoch [390/1000], Loss: 3219.7048\n",
            "Epoch [390/1000], Loss: 4479.2749\n",
            "Epoch [390/1000], Loss: 3915.1372\n",
            "Epoch [390/1000], Loss: 2804.9805\n",
            "Epoch [390/1000], Loss: 3244.2793\n",
            "Epoch [390/1000], Loss: 2682.6174\n",
            "Epoch [390/1000], Loss: 4708.98\n",
            "Epoch [400/1000], Loss: 3158.488\n",
            "Epoch [400/1000], Loss: 3524.1836\n",
            "Epoch [400/1000], Loss: 2772.3945\n",
            "Epoch [400/1000], Loss: 3701.5793\n",
            "Epoch [400/1000], Loss: 2889.3843\n",
            "Epoch [400/1000], Loss: 3606.5725\n",
            "Epoch [400/1000], Loss: 2809.5244\n",
            "Epoch [400/1000], Loss: 9406.0439\n",
            "Epoch [410/1000], Loss: 3275.325\n",
            "Epoch [410/1000], Loss: 2834.3127\n",
            "Epoch [410/1000], Loss: 4391.1328\n",
            "Epoch [410/1000], Loss: 3148.9307\n",
            "Epoch [410/1000], Loss: 3323.9456\n",
            "Epoch [410/1000], Loss: 2521.543\n",
            "Epoch [410/1000], Loss: 3415.1707\n",
            "Epoch [410/1000], Loss: 330.8382\n",
            "Epoch [420/1000], Loss: 3676.8699\n",
            "Epoch [420/1000], Loss: 3201.6418\n",
            "Epoch [420/1000], Loss: 3136.0627\n",
            "Epoch [420/1000], Loss: 3236.8503\n",
            "Epoch [420/1000], Loss: 3351.7444\n",
            "Epoch [420/1000], Loss: 3240.9934\n",
            "Epoch [420/1000], Loss: 2907.3999\n",
            "Epoch [420/1000], Loss: 1317.0273\n",
            "Epoch [430/1000], Loss: 2801.6016\n",
            "Epoch [430/1000], Loss: 3803.4705\n",
            "Epoch [430/1000], Loss: 3510.5981\n",
            "Epoch [430/1000], Loss: 2555.332\n",
            "Epoch [430/1000], Loss: 4251.8169\n",
            "Epoch [430/1000], Loss: 3296.4756\n",
            "Epoch [430/1000], Loss: 2019.6421\n",
            "Epoch [430/1000], Loss: 8094.5332\n",
            "Epoch [440/1000], Loss: 3850.0122\n",
            "Epoch [440/1000], Loss: 3148.9336\n",
            "Epoch [440/1000], Loss: 3480.4463\n",
            "Epoch [440/1000], Loss: 2734.5999\n",
            "Epoch [440/1000], Loss: 2894.3398\n",
            "Epoch [440/1000], Loss: 2754.7119\n",
            "Epoch [440/1000], Loss: 3166.7637\n",
            "Epoch [440/1000], Loss: 9833.4199\n",
            "Epoch [450/1000], Loss: 2873.9006\n",
            "Epoch [450/1000], Loss: 3599.0791\n",
            "Epoch [450/1000], Loss: 3043.3428\n",
            "Epoch [450/1000], Loss: 3620.0261\n",
            "Epoch [450/1000], Loss: 3798.0442\n",
            "Epoch [450/1000], Loss: 2980.7148\n",
            "Epoch [450/1000], Loss: 2592.6155\n",
            "Epoch [450/1000], Loss: 316.2054\n",
            "Epoch [460/1000], Loss: 3442.0486\n",
            "Epoch [460/1000], Loss: 2442.1194\n",
            "Epoch [460/1000], Loss: 2344.9919\n",
            "Epoch [460/1000], Loss: 4006.2581\n",
            "Epoch [460/1000], Loss: 2865.1599\n",
            "Epoch [460/1000], Loss: 3928.3037\n",
            "Epoch [460/1000], Loss: 2780.8918\n",
            "Epoch [460/1000], Loss: 10503.0342\n",
            "Epoch [470/1000], Loss: 3447.6941\n",
            "Epoch [470/1000], Loss: 2999.615\n",
            "Epoch [470/1000], Loss: 3642.4487\n",
            "Epoch [470/1000], Loss: 2355.688\n",
            "Epoch [470/1000], Loss: 3822.4924\n",
            "Epoch [470/1000], Loss: 2450.9536\n",
            "Epoch [470/1000], Loss: 3188.5403\n",
            "Epoch [470/1000], Loss: 7525.7393\n",
            "Epoch [480/1000], Loss: 2664.5134\n",
            "Epoch [480/1000], Loss: 2977.0659\n",
            "Epoch [480/1000], Loss: 2977.3599\n",
            "Epoch [480/1000], Loss: 3428.6096\n",
            "Epoch [480/1000], Loss: 3858.3823\n",
            "Epoch [480/1000], Loss: 2767.9236\n",
            "Epoch [480/1000], Loss: 3536.1311\n",
            "Epoch [480/1000], Loss: 1359.5284\n",
            "Epoch [490/1000], Loss: 3736.6345\n",
            "Epoch [490/1000], Loss: 2592.2356\n",
            "Epoch [490/1000], Loss: 4052.9917\n",
            "Epoch [490/1000], Loss: 2687.0349\n",
            "Epoch [490/1000], Loss: 3059.5237\n",
            "Epoch [490/1000], Loss: 3159.9709\n",
            "Epoch [490/1000], Loss: 2828.3108\n",
            "Epoch [490/1000], Loss: 1120.2286\n",
            "Epoch [500/1000], Loss: 2794.8101\n",
            "Epoch [500/1000], Loss: 2443.947\n",
            "Epoch [500/1000], Loss: 3467.2825\n",
            "Epoch [500/1000], Loss: 3729.3936\n",
            "Epoch [500/1000], Loss: 3330.3962\n",
            "Epoch [500/1000], Loss: 3132.8621\n",
            "Epoch [500/1000], Loss: 2860.1812\n",
            "Epoch [500/1000], Loss: 5925.1982\n",
            "Epoch [510/1000], Loss: 3360.2886\n",
            "Epoch [510/1000], Loss: 2852.5703\n",
            "Epoch [510/1000], Loss: 2977.6943\n",
            "Epoch [510/1000], Loss: 3986.7087\n",
            "Epoch [510/1000], Loss: 3128.8787\n",
            "Epoch [510/1000], Loss: 2760.1277\n",
            "Epoch [510/1000], Loss: 2870.52\n",
            "Epoch [510/1000], Loss: 1716.7234\n",
            "Epoch [520/1000], Loss: 2325.3716\n",
            "Epoch [520/1000], Loss: 3327.7493\n",
            "Epoch [520/1000], Loss: 3643.708\n",
            "Epoch [520/1000], Loss: 3329.1931\n",
            "Epoch [520/1000], Loss: 3173.9119\n",
            "Epoch [520/1000], Loss: 3512.4956\n",
            "Epoch [520/1000], Loss: 2413.2368\n",
            "Epoch [520/1000], Loss: 3913.0278\n",
            "Epoch [530/1000], Loss: 3417.6743\n",
            "Epoch [530/1000], Loss: 2493.6118\n",
            "Epoch [530/1000], Loss: 3431.5217\n",
            "Epoch [530/1000], Loss: 2961.4448\n",
            "Epoch [530/1000], Loss: 3954.46\n",
            "Epoch [530/1000], Loss: 2238.9707\n",
            "Epoch [530/1000], Loss: 3340.0549\n",
            "Epoch [530/1000], Loss: 1052.062\n",
            "Epoch [540/1000], Loss: 3119.02\n",
            "Epoch [540/1000], Loss: 3522.095\n",
            "Epoch [540/1000], Loss: 4362.0938\n",
            "Epoch [540/1000], Loss: 2580.5056\n",
            "Epoch [540/1000], Loss: 2800.8667\n",
            "Epoch [540/1000], Loss: 2913.4019\n",
            "Epoch [540/1000], Loss: 2476.9038\n",
            "Epoch [540/1000], Loss: 977.2584\n",
            "Epoch [550/1000], Loss: 3181.8743\n",
            "Epoch [550/1000], Loss: 2489.709\n",
            "Epoch [550/1000], Loss: 2396.5908\n",
            "Epoch [550/1000], Loss: 3599.4287\n",
            "Epoch [550/1000], Loss: 3357.6355\n",
            "Epoch [550/1000], Loss: 3207.8281\n",
            "Epoch [550/1000], Loss: 3237.3093\n",
            "Epoch [550/1000], Loss: 4961.6172\n",
            "Epoch [560/1000], Loss: 2830.9587\n",
            "Epoch [560/1000], Loss: 2806.2212\n",
            "Epoch [560/1000], Loss: 2390.3809\n",
            "Epoch [560/1000], Loss: 3254.5657\n",
            "Epoch [560/1000], Loss: 3280.8855\n",
            "Epoch [560/1000], Loss: 3626.1436\n",
            "Epoch [560/1000], Loss: 3492.749\n",
            "Epoch [560/1000], Loss: 463.5208\n",
            "Epoch [570/1000], Loss: 2718.8943\n",
            "Epoch [570/1000], Loss: 2861.1736\n",
            "Epoch [570/1000], Loss: 2475.3218\n",
            "Epoch [570/1000], Loss: 3046.9944\n",
            "Epoch [570/1000], Loss: 2796.3425\n",
            "Epoch [570/1000], Loss: 4281.9341\n",
            "Epoch [570/1000], Loss: 3408.2656\n",
            "Epoch [570/1000], Loss: 896.0521\n",
            "Epoch [580/1000], Loss: 2630.0493\n",
            "Epoch [580/1000], Loss: 4146.938\n",
            "Epoch [580/1000], Loss: 3250.0947\n",
            "Epoch [580/1000], Loss: 3222.3562\n",
            "Epoch [580/1000], Loss: 2944.8896\n",
            "Epoch [580/1000], Loss: 2862.2495\n",
            "Epoch [580/1000], Loss: 2479.3787\n",
            "Epoch [580/1000], Loss: 965.6986\n",
            "Epoch [590/1000], Loss: 3123.46\n",
            "Epoch [590/1000], Loss: 2994.1367\n",
            "Epoch [590/1000], Loss: 3255.4836\n",
            "Epoch [590/1000], Loss: 2717.8469\n",
            "Epoch [590/1000], Loss: 3169.803\n",
            "Epoch [590/1000], Loss: 2182.3291\n",
            "Epoch [590/1000], Loss: 3816.9639\n",
            "Epoch [590/1000], Loss: 4801.7827\n",
            "Epoch [600/1000], Loss: 3648.2917\n",
            "Epoch [600/1000], Loss: 4172.5698\n",
            "Epoch [600/1000], Loss: 3130.8049\n",
            "Epoch [600/1000], Loss: 2620.4001\n",
            "Epoch [600/1000], Loss: 2580.9875\n",
            "Epoch [600/1000], Loss: 2504.7192\n",
            "Epoch [600/1000], Loss: 2725.175\n",
            "Epoch [600/1000], Loss: 2010.2249\n",
            "Epoch [610/1000], Loss: 3530.3337\n",
            "Epoch [610/1000], Loss: 2859.0337\n",
            "Epoch [610/1000], Loss: 2185.4185\n",
            "Epoch [610/1000], Loss: 2591.8179\n",
            "Epoch [610/1000], Loss: 3615.6831\n",
            "Epoch [610/1000], Loss: 2885.2761\n",
            "Epoch [610/1000], Loss: 3461.3462\n",
            "Epoch [610/1000], Loss: 5615.4526\n",
            "Epoch [620/1000], Loss: 2922.8572\n",
            "Epoch [620/1000], Loss: 2093.9326\n",
            "Epoch [620/1000], Loss: 4518.3315\n",
            "Epoch [620/1000], Loss: 3000.2078\n",
            "Epoch [620/1000], Loss: 3068.2114\n",
            "Epoch [620/1000], Loss: 3057.3506\n",
            "Epoch [620/1000], Loss: 2710.5168\n",
            "Epoch [620/1000], Loss: 514.7737\n",
            "Epoch [630/1000], Loss: 2019.9919\n",
            "Epoch [630/1000], Loss: 4118.1509\n",
            "Epoch [630/1000], Loss: 3310.0205\n",
            "Epoch [630/1000], Loss: 2486.4905\n",
            "Epoch [630/1000], Loss: 3545.3525\n",
            "Epoch [630/1000], Loss: 2533.4143\n",
            "Epoch [630/1000], Loss: 3183.4912\n",
            "Epoch [630/1000], Loss: 2880.2312\n",
            "Epoch [640/1000], Loss: 2685.0515\n",
            "Epoch [640/1000], Loss: 2230.8242\n",
            "Epoch [640/1000], Loss: 2542.3376\n",
            "Epoch [640/1000], Loss: 3584.9558\n",
            "Epoch [640/1000], Loss: 3813.6128\n",
            "Epoch [640/1000], Loss: 3069.5425\n",
            "Epoch [640/1000], Loss: 3315.8975\n",
            "Epoch [640/1000], Loss: 1161.0752\n",
            "Epoch [650/1000], Loss: 2770.9878\n",
            "Epoch [650/1000], Loss: 3203.5898\n",
            "Epoch [650/1000], Loss: 2830.5356\n",
            "Epoch [650/1000], Loss: 3110.603\n",
            "Epoch [650/1000], Loss: 2969.895\n",
            "Epoch [650/1000], Loss: 2950.7288\n",
            "Epoch [650/1000], Loss: 2964.8354\n",
            "Epoch [650/1000], Loss: 7925.4507\n",
            "Epoch [660/1000], Loss: 3761.2349\n",
            "Epoch [660/1000], Loss: 3116.7004\n",
            "Epoch [660/1000], Loss: 2822.2588\n",
            "Epoch [660/1000], Loss: 3446.5498\n",
            "Epoch [660/1000], Loss: 2959.3174\n",
            "Epoch [660/1000], Loss: 2376.2771\n",
            "Epoch [660/1000], Loss: 2622.843\n",
            "Epoch [660/1000], Loss: 2113.9448\n",
            "Epoch [670/1000], Loss: 3531.45\n",
            "Epoch [670/1000], Loss: 3331.6812\n",
            "Epoch [670/1000], Loss: 2461.4761\n",
            "Epoch [670/1000], Loss: 2854.1323\n",
            "Epoch [670/1000], Loss: 3304.8909\n",
            "Epoch [670/1000], Loss: 3626.1831\n",
            "Epoch [670/1000], Loss: 1757.5425\n",
            "Epoch [670/1000], Loss: 5448.0996\n",
            "Epoch [680/1000], Loss: 2478.8459\n",
            "Epoch [680/1000], Loss: 3025.5486\n",
            "Epoch [680/1000], Loss: 2643.5571\n",
            "Epoch [680/1000], Loss: 3518.9062\n",
            "Epoch [680/1000], Loss: 2982.7354\n",
            "Epoch [680/1000], Loss: 3802.1143\n",
            "Epoch [680/1000], Loss: 2614.5972\n",
            "Epoch [680/1000], Loss: 1493.6985\n",
            "Epoch [690/1000], Loss: 2610.0979\n",
            "Epoch [690/1000], Loss: 2668.2981\n",
            "Epoch [690/1000], Loss: 4018.312\n",
            "Epoch [690/1000], Loss: 3041.937\n",
            "Epoch [690/1000], Loss: 3103.1167\n",
            "Epoch [690/1000], Loss: 2986.0024\n",
            "Epoch [690/1000], Loss: 2489.7266\n",
            "Epoch [690/1000], Loss: 3416.2456\n",
            "Epoch [700/1000], Loss: 2765.5105\n",
            "Epoch [700/1000], Loss: 3638.0889\n",
            "Epoch [700/1000], Loss: 2591.4067\n",
            "Epoch [700/1000], Loss: 3115.6309\n",
            "Epoch [700/1000], Loss: 2922.9692\n",
            "Epoch [700/1000], Loss: 2531.8044\n",
            "Epoch [700/1000], Loss: 3397.7588\n",
            "Epoch [700/1000], Loss: 2333.9507\n",
            "Epoch [710/1000], Loss: 2885.1965\n",
            "Epoch [710/1000], Loss: 2770.7253\n",
            "Epoch [710/1000], Loss: 3849.8611\n",
            "Epoch [710/1000], Loss: 2948.4341\n",
            "Epoch [710/1000], Loss: 3933.3262\n",
            "Epoch [710/1000], Loss: 2159.8059\n",
            "Epoch [710/1000], Loss: 2117.7717\n",
            "Epoch [710/1000], Loss: 6605.9043\n",
            "Epoch [720/1000], Loss: 3465.2786\n",
            "Epoch [720/1000], Loss: 2972.2075\n",
            "Epoch [720/1000], Loss: 2692.0139\n",
            "Epoch [720/1000], Loss: 3297.5173\n",
            "Epoch [720/1000], Loss: 2664.1475\n",
            "Epoch [720/1000], Loss: 2715.7109\n",
            "Epoch [720/1000], Loss: 3077.3086\n",
            "Epoch [720/1000], Loss: 2566.1145\n",
            "Epoch [730/1000], Loss: 3250.5393\n",
            "Epoch [730/1000], Loss: 2977.2869\n",
            "Epoch [730/1000], Loss: 3504.6992\n",
            "Epoch [730/1000], Loss: 2874.23\n",
            "Epoch [730/1000], Loss: 3202.2668\n",
            "Epoch [730/1000], Loss: 2001.4656\n",
            "Epoch [730/1000], Loss: 2777.0325\n",
            "Epoch [730/1000], Loss: 6961.1343\n",
            "Epoch [740/1000], Loss: 3415.2986\n",
            "Epoch [740/1000], Loss: 2737.813\n",
            "Epoch [740/1000], Loss: 1916.9855\n",
            "Epoch [740/1000], Loss: 3091.5598\n",
            "Epoch [740/1000], Loss: 4900.8135\n",
            "Epoch [740/1000], Loss: 2732.0996\n",
            "Epoch [740/1000], Loss: 2119.1511\n",
            "Epoch [740/1000], Loss: 1134.4082\n",
            "Epoch [750/1000], Loss: 2803.0762\n",
            "Epoch [750/1000], Loss: 2679.5493\n",
            "Epoch [750/1000], Loss: 4287.0933\n",
            "Epoch [750/1000], Loss: 3191.687\n",
            "Epoch [750/1000], Loss: 3141.2651\n",
            "Epoch [750/1000], Loss: 1950.5862\n",
            "Epoch [750/1000], Loss: 2742.3105\n",
            "Epoch [750/1000], Loss: 2643.7573\n",
            "Epoch [760/1000], Loss: 2174.7554\n",
            "Epoch [760/1000], Loss: 2447.6838\n",
            "Epoch [760/1000], Loss: 2673.2244\n",
            "Epoch [760/1000], Loss: 2898.7793\n",
            "Epoch [760/1000], Loss: 2837.2007\n",
            "Epoch [760/1000], Loss: 4580.3223\n",
            "Epoch [760/1000], Loss: 3088.8372\n",
            "Epoch [760/1000], Loss: 3946.645\n",
            "Epoch [770/1000], Loss: 2697.9556\n",
            "Epoch [770/1000], Loss: 3064.1536\n",
            "Epoch [770/1000], Loss: 3008.3875\n",
            "Epoch [770/1000], Loss: 3530.0999\n",
            "Epoch [770/1000], Loss: 2393.3684\n",
            "Epoch [770/1000], Loss: 2852.4634\n",
            "Epoch [770/1000], Loss: 3181.6699\n",
            "Epoch [770/1000], Loss: 3359.6853\n",
            "Epoch [780/1000], Loss: 2819.0537\n",
            "Epoch [780/1000], Loss: 2903.3799\n",
            "Epoch [780/1000], Loss: 3841.9631\n",
            "Epoch [780/1000], Loss: 3080.8738\n",
            "Epoch [780/1000], Loss: 2756.7678\n",
            "Epoch [780/1000], Loss: 2994.3782\n",
            "Epoch [780/1000], Loss: 2381.5168\n",
            "Epoch [780/1000], Loss: 1803.2988\n",
            "Epoch [790/1000], Loss: 2158.1462\n",
            "Epoch [790/1000], Loss: 3898.6394\n",
            "Epoch [790/1000], Loss: 2947.2168\n",
            "Epoch [790/1000], Loss: 3036.5105\n",
            "Epoch [790/1000], Loss: 3061.7532\n",
            "Epoch [790/1000], Loss: 2420.4275\n",
            "Epoch [790/1000], Loss: 3240.6274\n",
            "Epoch [790/1000], Loss: 1905.1394\n",
            "Epoch [800/1000], Loss: 2879.1558\n",
            "Epoch [800/1000], Loss: 3270.8894\n",
            "Epoch [800/1000], Loss: 3055.9944\n",
            "Epoch [800/1000], Loss: 3514.0947\n",
            "Epoch [800/1000], Loss: 1668.0834\n",
            "Epoch [800/1000], Loss: 3172.5918\n",
            "Epoch [800/1000], Loss: 3183.2769\n",
            "Epoch [800/1000], Loss: 1737.6479\n",
            "Epoch [810/1000], Loss: 2819.0444\n",
            "Epoch [810/1000], Loss: 3276.7312\n",
            "Epoch [810/1000], Loss: 2671.8882\n",
            "Epoch [810/1000], Loss: 3385.2422\n",
            "Epoch [810/1000], Loss: 2629.2568\n",
            "Epoch [810/1000], Loss: 3050.8894\n",
            "Epoch [810/1000], Loss: 2918.2102\n",
            "Epoch [810/1000], Loss: 1342.4927\n",
            "Epoch [820/1000], Loss: 3025.5999\n",
            "Epoch [820/1000], Loss: 2682.4609\n",
            "Epoch [820/1000], Loss: 2700.3774\n",
            "Epoch [820/1000], Loss: 3068.813\n",
            "Epoch [820/1000], Loss: 3579.8818\n",
            "Epoch [820/1000], Loss: 3038.7734\n",
            "Epoch [820/1000], Loss: 2632.4351\n",
            "Epoch [820/1000], Loss: 1279.9814\n",
            "Epoch [830/1000], Loss: 2973.5886\n",
            "Epoch [830/1000], Loss: 2654.8386\n",
            "Epoch [830/1000], Loss: 3059.4419\n",
            "Epoch [830/1000], Loss: 3107.3018\n",
            "Epoch [830/1000], Loss: 2112.9585\n",
            "Epoch [830/1000], Loss: 3336.168\n",
            "Epoch [830/1000], Loss: 3152.8362\n",
            "Epoch [830/1000], Loss: 6787.4141\n",
            "Epoch [840/1000], Loss: 3018.4917\n",
            "Epoch [840/1000], Loss: 3553.1165\n",
            "Epoch [840/1000], Loss: 3483.9121\n",
            "Epoch [840/1000], Loss: 2434.8354\n",
            "Epoch [840/1000], Loss: 3261.073\n",
            "Epoch [840/1000], Loss: 2736.1138\n",
            "Epoch [840/1000], Loss: 2263.4233\n",
            "Epoch [840/1000], Loss: 617.9362\n",
            "Epoch [850/1000], Loss: 2525.865\n",
            "Epoch [850/1000], Loss: 2979.248\n",
            "Epoch [850/1000], Loss: 3624.3467\n",
            "Epoch [850/1000], Loss: 2633.6694\n",
            "Epoch [850/1000], Loss: 2726.3481\n",
            "Epoch [850/1000], Loss: 3351.7378\n",
            "Epoch [850/1000], Loss: 2718.7192\n",
            "Epoch [850/1000], Loss: 3583.1074\n",
            "Epoch [860/1000], Loss: 1885.0742\n",
            "Epoch [860/1000], Loss: 2798.1987\n",
            "Epoch [860/1000], Loss: 1865.9026\n",
            "Epoch [860/1000], Loss: 3649.8262\n",
            "Epoch [860/1000], Loss: 3699.6196\n",
            "Epoch [860/1000], Loss: 3489.5613\n",
            "Epoch [860/1000], Loss: 3206.9468\n",
            "Epoch [860/1000], Loss: 2876.3132\n",
            "Epoch [870/1000], Loss: 2486.1997\n",
            "Epoch [870/1000], Loss: 2417.1353\n",
            "Epoch [870/1000], Loss: 3606.8171\n",
            "Epoch [870/1000], Loss: 3005.3496\n",
            "Epoch [870/1000], Loss: 2564.4209\n",
            "Epoch [870/1000], Loss: 3395.4873\n",
            "Epoch [870/1000], Loss: 3161.2603\n",
            "Epoch [870/1000], Loss: 2256.3369\n",
            "Epoch [880/1000], Loss: 2846.9937\n",
            "Epoch [880/1000], Loss: 3090.5286\n",
            "Epoch [880/1000], Loss: 3245.4009\n",
            "Epoch [880/1000], Loss: 2330.9944\n",
            "Epoch [880/1000], Loss: 3323.2559\n",
            "Epoch [880/1000], Loss: 3180.9766\n",
            "Epoch [880/1000], Loss: 2506.7683\n",
            "Epoch [880/1000], Loss: 3590.7842\n",
            "Epoch [890/1000], Loss: 2932.1062\n",
            "Epoch [890/1000], Loss: 2747.3318\n",
            "Epoch [890/1000], Loss: 3442.7495\n",
            "Epoch [890/1000], Loss: 3520.8428\n",
            "Epoch [890/1000], Loss: 2586.5149\n",
            "Epoch [890/1000], Loss: 2697.6267\n",
            "Epoch [890/1000], Loss: 2709.2712\n",
            "Epoch [890/1000], Loss: 1461.2162\n",
            "Epoch [900/1000], Loss: 2514.2454\n",
            "Epoch [900/1000], Loss: 4242.5269\n",
            "Epoch [900/1000], Loss: 2052.9453\n",
            "Epoch [900/1000], Loss: 1758.9026\n",
            "Epoch [900/1000], Loss: 3671.9758\n",
            "Epoch [900/1000], Loss: 3522.6174\n",
            "Epoch [900/1000], Loss: 2851.489\n",
            "Epoch [900/1000], Loss: 1449.7816\n",
            "Epoch [910/1000], Loss: 4068.7205\n",
            "Epoch [910/1000], Loss: 2451.175\n",
            "Epoch [910/1000], Loss: 2801.9668\n",
            "Epoch [910/1000], Loss: 3050.6367\n",
            "Epoch [910/1000], Loss: 3025.4736\n",
            "Epoch [910/1000], Loss: 2455.7793\n",
            "Epoch [910/1000], Loss: 2826.9902\n",
            "Epoch [910/1000], Loss: 194.9404\n",
            "Epoch [920/1000], Loss: 2811.2253\n",
            "Epoch [920/1000], Loss: 2787.5249\n",
            "Epoch [920/1000], Loss: 2671.8159\n",
            "Epoch [920/1000], Loss: 2854.7412\n",
            "Epoch [920/1000], Loss: 3454.4355\n",
            "Epoch [920/1000], Loss: 3186.3298\n",
            "Epoch [920/1000], Loss: 2799.2417\n",
            "Epoch [920/1000], Loss: 1924.3281\n",
            "Epoch [930/1000], Loss: 3421.293\n",
            "Epoch [930/1000], Loss: 2238.9199\n",
            "Epoch [930/1000], Loss: 3011.2324\n",
            "Epoch [930/1000], Loss: 3212.3994\n",
            "Epoch [930/1000], Loss: 3077.2036\n",
            "Epoch [930/1000], Loss: 2523.2778\n",
            "Epoch [930/1000], Loss: 2933.3162\n",
            "Epoch [930/1000], Loss: 4419.6587\n",
            "Epoch [940/1000], Loss: 3555.8372\n",
            "Epoch [940/1000], Loss: 2997.5493\n",
            "Epoch [940/1000], Loss: 3736.4377\n",
            "Epoch [940/1000], Loss: 2301.99\n",
            "Epoch [940/1000], Loss: 2195.3147\n",
            "Epoch [940/1000], Loss: 3170.9519\n",
            "Epoch [940/1000], Loss: 2601.2261\n",
            "Epoch [940/1000], Loss: 1751.5303\n",
            "Epoch [950/1000], Loss: 2650.1479\n",
            "Epoch [950/1000], Loss: 2565.0344\n",
            "Epoch [950/1000], Loss: 2789.5894\n",
            "Epoch [950/1000], Loss: 3511.3994\n",
            "Epoch [950/1000], Loss: 2780.8118\n",
            "Epoch [950/1000], Loss: 4054.5317\n",
            "Epoch [950/1000], Loss: 2203.0884\n",
            "Epoch [950/1000], Loss: 1798.6484\n",
            "Epoch [960/1000], Loss: 3060.0217\n",
            "Epoch [960/1000], Loss: 2864.5579\n",
            "Epoch [960/1000], Loss: 2850.2156\n",
            "Epoch [960/1000], Loss: 2923.929\n",
            "Epoch [960/1000], Loss: 2805.4419\n",
            "Epoch [960/1000], Loss: 3171.6367\n",
            "Epoch [960/1000], Loss: 2857.967\n",
            "Epoch [960/1000], Loss: 1874.7842\n",
            "Epoch [970/1000], Loss: 3098.7043\n",
            "Epoch [970/1000], Loss: 2829.3577\n",
            "Epoch [970/1000], Loss: 2912.199\n",
            "Epoch [970/1000], Loss: 1871.5598\n",
            "Epoch [970/1000], Loss: 3100.8291\n",
            "Epoch [970/1000], Loss: 3670.7556\n",
            "Epoch [970/1000], Loss: 3034.8706\n",
            "Epoch [970/1000], Loss: 2017.6465\n",
            "Epoch [980/1000], Loss: 2659.4917\n",
            "Epoch [980/1000], Loss: 3073.8955\n",
            "Epoch [980/1000], Loss: 2989.5681\n",
            "Epoch [980/1000], Loss: 2225.6296\n",
            "Epoch [980/1000], Loss: 4073.8042\n",
            "Epoch [980/1000], Loss: 2810.0793\n",
            "Epoch [980/1000], Loss: 2717.3208\n",
            "Epoch [980/1000], Loss: 1417.8252\n",
            "Epoch [990/1000], Loss: 2998.1736\n",
            "Epoch [990/1000], Loss: 2697.5017\n",
            "Epoch [990/1000], Loss: 3362.3003\n",
            "Epoch [990/1000], Loss: 3791.866\n",
            "Epoch [990/1000], Loss: 3156.4155\n",
            "Epoch [990/1000], Loss: 2211.4297\n",
            "Epoch [990/1000], Loss: 2322.8672\n",
            "Epoch [990/1000], Loss: 1440.3461\n",
            "Epoch [1000/1000], Loss: 3130.2483\n",
            "Epoch [1000/1000], Loss: 2505.3899\n",
            "Epoch [1000/1000], Loss: 2956.7861\n",
            "Epoch [1000/1000], Loss: 2812.4146\n",
            "Epoch [1000/1000], Loss: 2875.0898\n",
            "Epoch [1000/1000], Loss: 3196.4604\n",
            "Epoch [1000/1000], Loss: 2913.5173\n",
            "Epoch [1000/1000], Loss: 3816.3081\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "M1OR9uuhShfw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bda30358"
      },
      "source": [
        "### Evaluation after 1000 Epochs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2468fa68",
        "outputId": "5f104beb-89bd-4cb2-aa33-6c89a3db4338"
      },
      "source": [
        "model.eval() # Set the model to evaluation mode\n",
        "mse_values_1000_epochs = [] # Collect MSE scores\n",
        "\n",
        "with torch.no_grad():\n",
        "    for inputs, targets in test_loader:\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "        outputs = model(inputs) # Predict on test data\n",
        "\n",
        "        # Calculate Mean Squared Error for the batch\n",
        "        mse = criterion(outputs, targets)\n",
        "        mse_values_1000_epochs.append(mse.item())\n",
        "\n",
        "# Calculate and print the average MSE\n",
        "avg_mse_1000_epochs = np.mean(mse_values_1000_epochs)\n",
        "print(f\"Average MSE on test set after 1000 epochs: {avg_mse_1000_epochs}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average MSE on test set after 1000 epochs: 2862.158203125\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "6dbf5242",
        "outputId": "be87cf4f-1b8b-4117-efcf-6ae34612949a"
      },
      "source": [
        "# Collect predictions and actuals for comparison\n",
        "model.eval()\n",
        "predictions_1000_epochs = []\n",
        "actuals_1000_epochs = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for inputs, targets in test_loader:\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "        outputs = model(inputs)\n",
        "        predictions_1000_epochs.extend(outputs.cpu().numpy())\n",
        "        actuals_1000_epochs.extend(targets.cpu().numpy())\n",
        "\n",
        "# Create DataFrame for comparison\n",
        "results_df_1000_epochs = pd.DataFrame({'Predicted': np.array(predictions_1000_epochs).flatten(), 'Actual': np.array(actuals_1000_epochs).flatten()})\n",
        "display(results_df_1000_epochs)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "     Predicted  Actual\n",
              "0   143.103439   219.0\n",
              "1   178.147659    70.0\n",
              "2   139.159027   202.0\n",
              "3   295.722900   230.0\n",
              "4   123.695450   111.0\n",
              "..         ...     ...\n",
              "84  115.172958   153.0\n",
              "85   87.421288    98.0\n",
              "86   78.077057    37.0\n",
              "87   64.696053    63.0\n",
              "88  155.820312   184.0\n",
              "\n",
              "[89 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-528ff368-d02f-4a0d-91a4-946e2f1e56e5\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Predicted</th>\n",
              "      <th>Actual</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>143.103439</td>\n",
              "      <td>219.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>178.147659</td>\n",
              "      <td>70.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>139.159027</td>\n",
              "      <td>202.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>295.722900</td>\n",
              "      <td>230.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>123.695450</td>\n",
              "      <td>111.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>84</th>\n",
              "      <td>115.172958</td>\n",
              "      <td>153.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>85</th>\n",
              "      <td>87.421288</td>\n",
              "      <td>98.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>86</th>\n",
              "      <td>78.077057</td>\n",
              "      <td>37.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>87</th>\n",
              "      <td>64.696053</td>\n",
              "      <td>63.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88</th>\n",
              "      <td>155.820312</td>\n",
              "      <td>184.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>89 rows Ã— 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-528ff368-d02f-4a0d-91a4-946e2f1e56e5')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-528ff368-d02f-4a0d-91a4-946e2f1e56e5 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-528ff368-d02f-4a0d-91a4-946e2f1e56e5');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-ae6bd676-693d-4691-8a45-02fd987b2d31\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ae6bd676-693d-4691-8a45-02fd987b2d31')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-ae6bd676-693d-4691-8a45-02fd987b2d31 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_7ef8203d-b036-4e2c-ad9c-9887b2e3ce75\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('results_df_1000_epochs')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_7ef8203d-b036-4e2c-ad9c-9887b2e3ce75 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('results_df_1000_epochs');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "results_df_1000_epochs",
              "summary": "{\n  \"name\": \"results_df_1000_epochs\",\n  \"rows\": 89,\n  \"fields\": [\n    {\n      \"column\": \"Predicted\",\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"num_unique_values\": 89,\n        \"samples\": [\n          177.3844757080078,\n          110.56366729736328,\n          177.12660217285156\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Actual\",\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"num_unique_values\": 75,\n        \"samples\": [\n          111.0,\n          61.0,\n          252.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The average Mean Squarred Error (MSE) for the model with 1,000 epochs is significantly lower. It is **2862.158**, significantly lower than **15769.965** of the model with 100 epochs. This means that training for more epochs increased the model's performance."
      ],
      "metadata": {
        "id": "sJTsTb1rTD69"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Exercise 2"
      ],
      "metadata": {
        "id": "svw-E4NGT0xY"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lRS4vueZT3f2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bfef4e36"
      },
      "source": [
        "# Task\n",
        "The user wants to compare different neural network architectures for the diabetes prediction task. I will proceed with the following steps:\n",
        "\n",
        "1.  **Define Model with More Neurons (`DiabetesModelV2`)**: Create a new model class `DiabetesModelV2` with an increased number of neurons (e.g., from 5 to 10) in its hidden layers.\n",
        "2.  **Train Model V2**: Initialize `DiabetesModelV2` and train it for 1000 epochs using the same `MSELoss` criterion and `Adam` optimizer as the original model. Print the loss every 10 epochs.\n",
        "3.  **Evaluate Model V2**: Evaluate the trained `DiabetesModelV2` on the test set, calculate its average MSE, and display a DataFrame comparing predicted versus actual values.\n",
        "4.  **Define Model with More Layers (`DiabetesModelV3`)**: Create another new model class `DiabetesModelV3` by adding an additional hidden layer (e.g., three hidden layers instead of two), potentially adjusting the number of neurons if needed for comparison (keeping them at 10 per layer to isolate layer effect from neuron count effect).\n",
        "5.  **Train Model V3**: Initialize `DiabetesModelV3` and train it for 1000 epochs using the same criterion and optimizer. Print the loss every 10 epochs.\n",
        "6.  **Evaluate Model V3**: Evaluate the trained `DiabetesModelV3` on the test set, calculate its average MSE, and display a DataFrame comparing predicted versus actual values.\n",
        "7.  **Compare Architectures and Summarize**: Compare the average MSE values from the original `DiabetesModel`, `DiabetesModelV2`, and `DiabetesModelV3` to determine which architecture performs best and provide a summary of the findings.\n",
        "\n",
        "This will directly address Exercise #2 and provide a comprehensive comparison of different model architectures."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ff7db6c4"
      },
      "source": [
        "## Define Model with More Neurons\n",
        "\n",
        "### Subtask:\n",
        "Define a new `DiabetesModel` class (e.g., `DiabetesModelV2`) that increases the number of neurons in the existing hidden layers (e.g., from 5 to 10 or more) to see its impact on performance.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ea67cbad"
      },
      "source": [
        "**Reasoning**:\n",
        "To address the subtask of defining a new model with more neurons, I will create a new Python class `DiabetesModelV2` that follows the specified architecture with increased neuron counts in its hidden layers.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dc014e23",
        "outputId": "5afb9939-be39-4fdc-bd44-cf2e182285f2"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# Define the new model with more neurons\n",
        "class DiabetesModelV2(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(DiabetesModelV2, self).__init__()\n",
        "        self.layers = nn.Sequential(\n",
        "            nn.Linear(10, 10), # First layer with 10 input features and 10 neurons\n",
        "            nn.ReLU(),         # ReLU activation\n",
        "            nn.Linear(10, 10), # Second linear layer with 10 input and 10 output neurons\n",
        "            nn.ReLU(),         # ReLU activation\n",
        "            nn.Linear(10, 1)   # Output layer for regression (1 neuron)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.layers(x)\n",
        "\n",
        "print(\"DiabetesModelV2 class defined with 10 neurons in hidden layers.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DiabetesModelV2 class defined with 10 neurons in hidden layers.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "baad51f6"
      },
      "source": [
        "## Train Model V2\n",
        "\n",
        "### Subtask:\n",
        "Initialize and train the `DiabetesModelV2` using `MSELoss` and `Adam` optimizer for 1000 epochs, similar to the training process for the original model. Evaluate the model's performance on the test set and collect predictions for comparison.\n",
        "\n",
        "#### Instructions\n",
        "1. Initialize an instance of `DiabetesModelV2`.\n",
        "2. Define the `MSELoss` criterion and `Adam` optimizer with a learning rate of 0.001.\n",
        "3. Train the model for 1000 epochs, moving data and model to the GPU if available.\n",
        "4. Print the loss every 10 epochs during training.\n",
        "5. After training, set the model to evaluation mode (`model.eval()`).\n",
        "6. Predict on the `test_loader` and calculate the average MSE on the test set.\n",
        "7. Store the predictions and actual values in separate lists.\n",
        "8. Create a pandas DataFrame to display the predicted vs. actual values for `DiabetesModelV2`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dc36e5d1"
      },
      "source": [
        "**Reasoning**:\n",
        "This code block initializes `DiabetesModelV2`, sets up the `MSELoss` criterion and `Adam` optimizer, and then trains the model for 1000 epochs, printing the loss every 10 epochs. It also handles moving the model and data to the GPU.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3958cd8e",
        "outputId": "80e374c8-492f-45dd-e0b0-6bc6c5900476"
      },
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "# Initialize the model, loss function, and optimizer for V2\n",
        "model_v2 = DiabetesModelV2()\n",
        "criterion_v2 = nn.MSELoss()\n",
        "optimiser_v2 = optim.Adam(model_v2.parameters(), lr=0.001)\n",
        "\n",
        "# Move model to GPU if available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Training loop for DiabetesModelV2\n",
        "epochs_v2 = 1000\n",
        "\n",
        "print(f\"\\n--- Training DiabetesModelV2 for {epochs_v2} epochs ---\")\n",
        "for epoch in range(epochs_v2):\n",
        "    for inputs, targets in train_loader:\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "        model_v2.to(device)\n",
        "\n",
        "        model_v2.train()\n",
        "        optimiser_v2.zero_grad()\n",
        "        outputs = model_v2(inputs)\n",
        "        loss = criterion_v2(outputs, targets)\n",
        "        loss.backward()\n",
        "        optimiser_v2.step()\n",
        "\n",
        "    if (epoch + 1) % 100 == 0: # Print loss every 100 epochs to reduce output verbosity\n",
        "        print(f'Epoch [{epoch+1}/{epochs_v2}], Loss: {round(loss.item(), 4)}')\n",
        "\n",
        "print(\"Training of DiabetesModelV2 complete.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Training DiabetesModelV2 for 1000 epochs ---\n",
            "Epoch [100/1000], Loss: 17883.3633\n",
            "Epoch [200/1000], Loss: 6449.209\n",
            "Epoch [300/1000], Loss: 3713.7664\n",
            "Epoch [400/1000], Loss: 2414.8076\n",
            "Epoch [500/1000], Loss: 4811.603\n",
            "Epoch [600/1000], Loss: 3185.7031\n",
            "Epoch [700/1000], Loss: 2111.4668\n",
            "Epoch [800/1000], Loss: 2584.8682\n",
            "Epoch [900/1000], Loss: 810.4833\n",
            "Epoch [1000/1000], Loss: 736.0966\n",
            "Training of DiabetesModelV2 complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8079d763"
      },
      "source": [
        "**Reasoning**:\n",
        "Now that `DiabetesModelV2` has been trained, I need to evaluate its performance on the test set by calculating the average MSE and collecting its predictions against actual values. This directly follows the instructions for the 'Train Model V2' subtask.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 441
        },
        "id": "e6c825ab",
        "outputId": "4038e84a-440d-469b-bffb-99e90379c118"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Evaluate Model V2\n",
        "model_v2.eval() # Set the model to evaluation mode\n",
        "mse_values_v2 = [] # Collect MSE scores\n",
        "predictions_v2 = []\n",
        "actuals_v2 = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for inputs, targets in test_loader:\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "        outputs = model_v2(inputs) # Predict on test data\n",
        "\n",
        "        # Calculate Mean Squared Error for the batch\n",
        "        mse = criterion_v2(outputs, targets)\n",
        "        mse_values_v2.append(mse.item())\n",
        "\n",
        "        predictions_v2.extend(outputs.cpu().numpy())\n",
        "        actuals_v2.extend(targets.cpu().numpy())\n",
        "\n",
        "# Calculate and print the average MSE\n",
        "avg_mse_v2 = np.mean(mse_values_v2)\n",
        "print(f\"Average MSE on test set for DiabetesModelV2 (1000 epochs, 10 neurons): {avg_mse_v2:.4f}\")\n",
        "\n",
        "# Create DataFrame for comparison\n",
        "results_df_v2 = pd.DataFrame({'Predicted': np.array(predictions_v2).flatten(), 'Actual': np.array(actuals_v2).flatten()})\n",
        "display(results_df_v2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average MSE on test set for DiabetesModelV2 (1000 epochs, 10 neurons): 2843.2891\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "     Predicted  Actual\n",
              "0   146.717316   219.0\n",
              "1   177.446732    70.0\n",
              "2   142.100739   202.0\n",
              "3   296.422424   230.0\n",
              "4   127.108032   111.0\n",
              "..         ...     ...\n",
              "84  117.634277   153.0\n",
              "85   88.824753    98.0\n",
              "86   78.634583    37.0\n",
              "87   66.724464    63.0\n",
              "88  155.182129   184.0\n",
              "\n",
              "[89 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-745f438f-7cd6-4d43-a2a1-62220021be02\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Predicted</th>\n",
              "      <th>Actual</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>146.717316</td>\n",
              "      <td>219.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>177.446732</td>\n",
              "      <td>70.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>142.100739</td>\n",
              "      <td>202.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>296.422424</td>\n",
              "      <td>230.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>127.108032</td>\n",
              "      <td>111.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>84</th>\n",
              "      <td>117.634277</td>\n",
              "      <td>153.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>85</th>\n",
              "      <td>88.824753</td>\n",
              "      <td>98.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>86</th>\n",
              "      <td>78.634583</td>\n",
              "      <td>37.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>87</th>\n",
              "      <td>66.724464</td>\n",
              "      <td>63.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88</th>\n",
              "      <td>155.182129</td>\n",
              "      <td>184.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>89 rows Ã— 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-745f438f-7cd6-4d43-a2a1-62220021be02')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-745f438f-7cd6-4d43-a2a1-62220021be02 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-745f438f-7cd6-4d43-a2a1-62220021be02');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-b8afcf30-7eda-413b-94ac-a3d32a529d45\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b8afcf30-7eda-413b-94ac-a3d32a529d45')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-b8afcf30-7eda-413b-94ac-a3d32a529d45 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_08a8a0f5-2bb2-4782-8c4c-0f5ae453f20b\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('results_df_v2')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_08a8a0f5-2bb2-4782-8c4c-0f5ae453f20b button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('results_df_v2');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "results_df_v2",
              "summary": "{\n  \"name\": \"results_df_v2\",\n  \"rows\": 89,\n  \"fields\": [\n    {\n      \"column\": \"Predicted\",\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"num_unique_values\": 89,\n        \"samples\": [\n          179.16659545898438,\n          112.57621002197266,\n          176.99652099609375\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Actual\",\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"num_unique_values\": 75,\n        \"samples\": [\n          111.0,\n          61.0,\n          252.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "481a9c2c"
      },
      "source": [
        "## Define Model with More Layers\n",
        "\n",
        "### Subtask:\n",
        "Define a new `DiabetesModel` class (e.g., `DiabetesModelV3`) that adds an additional hidden layer to the architecture, potentially adjusting the number of neurons to maintain consistency or explore further changes.\n",
        "\n",
        "#### Instructions\n",
        "1. Define a new Python class named `DiabetesModelV3` that inherits from `nn.Module`.\n",
        "2. Inside the `__init__` method, set up the layers using `nn.Sequential`.\n",
        "3. The first linear layer should take 10 features as input and output 10 neurons.\n",
        "4. Include a `nn.ReLU()` activation function after the first linear layer.\n",
        "5. Add a *second* linear layer that takes 10 neurons as input and outputs 10 neurons.\n",
        "6. Include a `nn.ReLU()` activation function after the second linear layer.\n",
        "7. Add a *third* linear layer that takes 10 neurons as input and outputs 10 neurons.\n",
        "8. Include a `nn.ReLU()` activation function after the third linear layer.\n",
        "9. The final linear layer should take 10 neurons as input and output 1 neuron (for regression).\n",
        "10. Implement the `forward` method to pass the input `x` through the defined layers."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "04a86a0d"
      },
      "source": [
        "**Reasoning**:\n",
        "To implement the `DiabetesModelV3` as described, I will create a Python class that extends `nn.Module` and defines three hidden layers, each followed by a ReLU activation, and an output layer.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "10600392",
        "outputId": "c3bfe8be-f956-41a1-fcb9-f348a1f5e1cf"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# Define the new model with more layers\n",
        "class DiabetesModelV3(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(DiabetesModelV3, self).__init__()\n",
        "        self.layers = nn.Sequential(\n",
        "            nn.Linear(10, 10), # First hidden layer with 10 neurons\n",
        "            nn.ReLU(),         # ReLU activation\n",
        "            nn.Linear(10, 10), # Second hidden layer with 10 neurons\n",
        "            nn.ReLU(),         # ReLU activation\n",
        "            nn.Linear(10, 10), # Third hidden layer with 10 neurons\n",
        "            nn.ReLU(),         # ReLU activation\n",
        "            nn.Linear(10, 1)   # Output layer for regression (1 neuron)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.layers(x)\n",
        "\n",
        "print(\"DiabetesModelV3 class defined with 3 hidden layers, each with 10 neurons.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DiabetesModelV3 class defined with 3 hidden layers, each with 10 neurons.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8eb343cf"
      },
      "source": [
        "## Train Model V3\n",
        "\n",
        "### Subtask:\n",
        "Initialize and train the `DiabetesModelV3` using `MSELoss` and `Adam` optimizer for 1000 epochs, similar to the training process for the previous models. Evaluate the model's performance on the test set and collect predictions for comparison.\n",
        "\n",
        "#### Instructions\n",
        "1. Initialize an instance of `DiabetesModelV3`.\n",
        "2. Define the `MSELoss` criterion and `Adam` optimizer with a learning rate of 0.001.\n",
        "3. Train the model for 1000 epochs, moving data and model to the GPU if available.\n",
        "4. Print the loss every 100 epochs during training to reduce verbosity.\n",
        "5. After training, set the model to evaluation mode (`model.eval()`).\n",
        "6. Predict on the `test_loader` and calculate the average MSE on the test set.\n",
        "7. Store the predictions and actual values in separate lists.\n",
        "8. Create a pandas DataFrame to display the predicted vs. actual values for `DiabetesModelV3`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a28be8ed"
      },
      "source": [
        "**Reasoning**:\n",
        "This code block initializes `DiabetesModelV3`, sets up the `MSELoss` criterion and `Adam` optimizer, and then trains the model for 1000 epochs, printing the loss every 100 epochs. It also handles moving the model and data to the GPU, as per the instructions for the 'Train Model V3' subtask.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b294f049",
        "outputId": "35d40eee-8a29-4d77-bde4-5ce75b543c64"
      },
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "# Initialize the model, loss function, and optimizer for V3\n",
        "model_v3 = DiabetesModelV3()\n",
        "criterion_v3 = nn.MSELoss()\n",
        "optimiser_v3 = optim.Adam(model_v3.parameters(), lr=0.001)\n",
        "\n",
        "# Move model to GPU if available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Training loop for DiabetesModelV3\n",
        "epochs_v3 = 1000\n",
        "\n",
        "print(f\"\\n--- Training DiabetesModelV3 for {epochs_v3} epochs ---\")\n",
        "for epoch in range(epochs_v3):\n",
        "    for inputs, targets in train_loader:\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "        model_v3.to(device)\n",
        "\n",
        "        model_v3.train()\n",
        "        optimiser_v3.zero_grad()\n",
        "        outputs = model_v3(inputs)\n",
        "        loss = criterion_v3(outputs, targets)\n",
        "        loss.backward()\n",
        "        optimiser_v3.step()\n",
        "\n",
        "    if (epoch + 1) % 100 == 0: # Print loss every 100 epochs to reduce output verbosity\n",
        "        print(f'Epoch [{epoch+1}/{epochs_v3}], Loss: {round(loss.item(), 4)}')\n",
        "\n",
        "print(\"Training of DiabetesModelV3 complete.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Training DiabetesModelV3 for 1000 epochs ---\n",
            "Epoch [100/1000], Loss: 3490.6616\n",
            "Epoch [200/1000], Loss: 585.2907\n",
            "Epoch [300/1000], Loss: 1549.8417\n",
            "Epoch [400/1000], Loss: 2091.2622\n",
            "Epoch [500/1000], Loss: 2362.8462\n",
            "Epoch [600/1000], Loss: 322.7177\n",
            "Epoch [700/1000], Loss: 926.8246\n",
            "Epoch [800/1000], Loss: 2824.238\n",
            "Epoch [900/1000], Loss: 3048.1313\n",
            "Epoch [1000/1000], Loss: 6025.7163\n",
            "Training of DiabetesModelV3 complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3cde71f3"
      },
      "source": [
        "**Reasoning**:\n",
        "Now that `DiabetesModelV3` has been trained, I need to evaluate its performance on the test set by calculating the average MSE and collecting its predictions against actual values. This directly follows the instructions for the 'Train Model V3' subtask.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 441
        },
        "id": "4388582b",
        "outputId": "b0d369a5-29c0-4074-a841-73faf6f7cdef"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Evaluate Model V3\n",
        "model_v3.eval() # Set the model to evaluation mode\n",
        "mse_values_v3 = [] # Collect MSE scores\n",
        "predictions_v3 = []\n",
        "actuals_v3 = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for inputs, targets in test_loader:\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "        outputs = model_v3(inputs) # Predict on test data\n",
        "\n",
        "        # Calculate Mean Squared Error for the batch\n",
        "        mse = criterion_v3(outputs, targets)\n",
        "        mse_values_v3.append(mse.item())\n",
        "\n",
        "        predictions_v3.extend(outputs.cpu().numpy())\n",
        "        actuals_v3.extend(targets.cpu().numpy())\n",
        "\n",
        "# Calculate and print the average MSE\n",
        "avg_mse_v3 = np.mean(mse_values_v3)\n",
        "print(f\"Average MSE on test set for DiabetesModelV3 (1000 epochs, 3 hidden layers, 10 neurons each): {avg_mse_v3:.4f}\")\n",
        "\n",
        "# Create DataFrame for comparison\n",
        "results_df_v3 = pd.DataFrame({'Predicted': np.array(predictions_v3).flatten(), 'Actual': np.array(actuals_v3).flatten()})\n",
        "display(results_df_v3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average MSE on test set for DiabetesModelV3 (1000 epochs, 3 hidden layers, 10 neurons each): 2846.4318\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "     Predicted  Actual\n",
              "0   139.515396   219.0\n",
              "1   180.437225    70.0\n",
              "2   137.777679   202.0\n",
              "3   298.653076   230.0\n",
              "4   119.126602   111.0\n",
              "..         ...     ...\n",
              "84  110.241539   153.0\n",
              "85   84.649307    98.0\n",
              "86   79.792465    37.0\n",
              "87   65.981644    63.0\n",
              "88  161.153152   184.0\n",
              "\n",
              "[89 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ee353883-454a-4b12-9995-c13cb2ad3837\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Predicted</th>\n",
              "      <th>Actual</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>139.515396</td>\n",
              "      <td>219.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>180.437225</td>\n",
              "      <td>70.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>137.777679</td>\n",
              "      <td>202.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>298.653076</td>\n",
              "      <td>230.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>119.126602</td>\n",
              "      <td>111.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>84</th>\n",
              "      <td>110.241539</td>\n",
              "      <td>153.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>85</th>\n",
              "      <td>84.649307</td>\n",
              "      <td>98.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>86</th>\n",
              "      <td>79.792465</td>\n",
              "      <td>37.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>87</th>\n",
              "      <td>65.981644</td>\n",
              "      <td>63.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88</th>\n",
              "      <td>161.153152</td>\n",
              "      <td>184.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>89 rows Ã— 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ee353883-454a-4b12-9995-c13cb2ad3837')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-ee353883-454a-4b12-9995-c13cb2ad3837 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-ee353883-454a-4b12-9995-c13cb2ad3837');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-8029eed3-0256-4790-a2c8-750b3419f12a\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-8029eed3-0256-4790-a2c8-750b3419f12a')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-8029eed3-0256-4790-a2c8-750b3419f12a button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_cb192e93-bbb6-4b00-b2bf-8a29585a9d52\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('results_df_v3')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_cb192e93-bbb6-4b00-b2bf-8a29585a9d52 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('results_df_v3');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "results_df_v3",
              "summary": "{\n  \"name\": \"results_df_v3\",\n  \"rows\": 89,\n  \"fields\": [\n    {\n      \"column\": \"Predicted\",\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"num_unique_values\": 89,\n        \"samples\": [\n          175.71070861816406,\n          106.76041412353516,\n          179.74725341796875\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Actual\",\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"num_unique_values\": 75,\n        \"samples\": [\n          111.0,\n          61.0,\n          252.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eafa8d32"
      },
      "source": [
        "**Reasoning**:\n",
        "All models (original with 1000 epochs, V2 with more neurons, and V3 with more layers) have been trained and evaluated. The final step for Exercise #2 is to compare their average MSEs and summarize the findings to determine the best-performing architecture.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "003618ca",
        "outputId": "2ee560da-0cd4-4d3c-b2c2-b2d60aa3ff40"
      },
      "source": [
        "print(\"\\n--- Architecture Comparison ---\")\n",
        "print(f\"Original DiabetesModel (1000 epochs, 5 neurons per layer): Average MSE = {avg_mse_1000_epochs:.4f}\")\n",
        "print(f\"DiabetesModelV2 (1000 epochs, 10 neurons per layer): Average MSE = {avg_mse_v2:.4f}\")\n",
        "print(f\"DiabetesModelV3 (1000 epochs, 3 hidden layers, 10 neurons each): Average MSE = {avg_mse_v3:.4f}\")\n",
        "\n",
        "# Determine the best performing model\n",
        "best_mse = min(avg_mse_1000_epochs, avg_mse_v2, avg_mse_v3)\n",
        "\n",
        "if best_mse == avg_mse_1000_epochs:\n",
        "    best_model_name = \"Original DiabetesModel (1000 epochs)\"\n",
        "elif best_mse == avg_mse_v2:\n",
        "    best_model_name = \"DiabetesModelV2 (10 neurons per layer)\"\n",
        "else:\n",
        "    best_model_name = \"DiabetesModelV3 (3 hidden layers)\"\n",
        "\n",
        "print(f\"\\nThe best performing model based on average MSE is: {best_model_name} with an MSE of {best_mse:.4f}\")\n",
        "print(\"\\nSummary: Increasing the number of epochs from 100 to 1000 significantly improved performance across all architectures. Comparing the models trained for 1000 epochs:\")\n",
        "print(\"- DiabetesModelV2 (more neurons) shows a slight improvement over the original model (with 1000 epochs).\")\n",
        "print(\"- DiabetesModelV3 (more layers) shows comparable performance to DiabetesModelV2.\")\n",
        "print(\"These results suggest that for this dataset, increasing neurons or layers beyond a certain point might not yield significant further improvements without other optimizations (e.g., hyperparameter tuning, different activation functions, regularization).\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Architecture Comparison ---\n",
            "Original DiabetesModel (1000 epochs, 5 neurons per layer): Average MSE = 2862.1582\n",
            "DiabetesModelV2 (1000 epochs, 10 neurons per layer): Average MSE = 2843.2891\n",
            "DiabetesModelV3 (1000 epochs, 3 hidden layers, 10 neurons each): Average MSE = 2846.4318\n",
            "\n",
            "The best performing model based on average MSE is: DiabetesModelV2 (10 neurons per layer) with an MSE of 2843.2891\n",
            "\n",
            "Summary: Increasing the number of epochs from 100 to 1000 significantly improved performance across all architectures. Comparing the models trained for 1000 epochs:\n",
            "- DiabetesModelV2 (more neurons) shows a slight improvement over the original model (with 1000 epochs).\n",
            "- DiabetesModelV3 (more layers) shows comparable performance to DiabetesModelV2.\n",
            "These results suggest that for this dataset, increasing neurons or layers beyond a certain point might not yield significant further improvements without other optimizations (e.g., hyperparameter tuning, different activation functions, regularization).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ab3c384"
      },
      "source": [
        "## Final Task\n",
        "\n",
        "### Subtask:\n",
        "Summarize the experimentation with different architectures and present the conclusion about the optimal architecture found.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ee97c725"
      },
      "source": [
        "## Summary:\n",
        "\n",
        "### Q&A\n",
        "The experimentation with different architectures led to the conclusion that `DiabetesModelV2`, which incorporates more neurons (10 per hidden layer) than the original model, is the optimal architecture among those tested for this task. It achieved the lowest average Mean Squared Error (MSE) on the test set.\n",
        "\n",
        "### Data Analysis Key Findings\n",
        "*   **Original `DiabetesModel` (1000 epochs, 5 neurons per layer):** Achieved an average MSE of `2862.1582` on the test set.\n",
        "*   **`DiabetesModelV2` (More Neurons - 10 per layer):** Achieved the lowest average MSE of `2843.2891` on the test set, showing a slight improvement over the original model.\n",
        "*   **`DiabetesModelV3` (More Layers - 3 hidden layers, 10 neurons each):** Achieved an average MSE of `2846.4318` on the test set, performing comparably to `DiabetesModelV2`.\n",
        "*   **Optimal Architecture:** `DiabetesModelV2` with 10 neurons per hidden layer demonstrated the best performance among the three tested architectures.\n",
        "\n",
        "### Insights or Next Steps\n",
        "*   For this specific dataset, simply increasing the number of neurons or layers beyond `DiabetesModelV2`'s configuration did not yield substantial further improvements in MSE.\n",
        "*   Future work should focus on other optimization techniques such as hyperparameter tuning (e.g., learning rate, batch size), exploring different activation functions, or implementing regularization methods to potentially achieve better performance.\n"
      ]
    }
  ]
}